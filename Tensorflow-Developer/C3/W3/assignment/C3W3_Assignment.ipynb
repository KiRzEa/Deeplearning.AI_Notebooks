{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "printable-split",
   "metadata": {},
   "source": [
    "\n",
    "# Week 3: Exploring Overfitting in NLP\n",
    "\n",
    "Welcome to this assignment! During this week you saw different ways to handle sequence-like data. You saw how some Keras' layers such as `GRU`, `Conv` and `LSTM` can be used to tackle problems in this space. Now you will put this knowledge into practice by creating a model architecture that does not overfit.\n",
    "\n",
    "For this assignment you will be using a variation of the [Sentiment140 dataset](http://help.sentiment140.com/home), which contains 1.6 million tweets alongside their respective sentiment (0 for negative and 4 for positive).\n",
    "\n",
    "You will also need to create the helper functions very similar to the ones you coded in previous assignments pre-process data and to tokenize sentences. However the objective of the assignment is to find a model architecture that will not overfit.\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "greater-synthesis",
   "metadata": {
    "id": "hmA6EzkQJ5jt",
    "tags": [
     "graded"
    ]
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "partially initialized module 'pandas' has no attribute 'core' (most likely due to a circular import)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpickle\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Tokenizer\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msequence\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pad_sequences\n",
      "File \u001b[1;32mC:\\Users\\Public\\anaconda\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\__init__.py:469\u001b[0m\n\u001b[0;32m    467\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(_current_module, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeras\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    468\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 469\u001b[0m     \u001b[43m_keras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    470\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[0;32m    471\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Users\\Public\\anaconda\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\util\\lazy_loader.py:41\u001b[0m, in \u001b[0;36mLazyLoader._load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;124;03m\"\"\"Load the module and insert it into the parent's globals.\"\"\"\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# Import the target module and insert it into the parent's namespace\u001b[39;00m\n\u001b[1;32m---> 41\u001b[0m module \u001b[38;5;241m=\u001b[39m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parent_module_globals[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_local_name] \u001b[38;5;241m=\u001b[39m module\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m# Emit a warning if one was specified\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Users\\Public\\anaconda\\envs\\tf-gpu\\lib\\importlib\\__init__.py:127\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m    125\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    126\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m--> 127\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Users\\Public\\anaconda\\envs\\tf-gpu\\lib\\site-packages\\keras\\__init__.py:21\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Implementation of the Keras API, the high-level API of TensorFlow.\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \n\u001b[0;32m     17\u001b[0m \u001b[38;5;124;03mDetailed documentation and user guides are available at\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;124;03m[keras.io](https://keras.io).\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m distribute\n\u001b[1;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m models\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minput_layer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Input\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msequential\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential\n",
      "File \u001b[1;32mC:\\Users\\Public\\anaconda\\envs\\tf-gpu\\lib\\site-packages\\keras\\models\\__init__.py:18\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2022 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# ==============================================================================\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Keras models API.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Functional\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msequential\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtraining\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Model\n",
      "File \u001b[1;32mC:\\Users\\Public\\anaconda\\envs\\tf-gpu\\lib\\site-packages\\keras\\engine\\functional.py:34\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m input_spec\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m node \u001b[38;5;28;01mas\u001b[39;00m node_module\n\u001b[1;32m---> 34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m training \u001b[38;5;28;01mas\u001b[39;00m training_lib\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m training_utils\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaving\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaved_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m json_utils\n",
      "File \u001b[1;32mC:\\Users\\Public\\anaconda\\envs\\tf-gpu\\lib\\site-packages\\keras\\engine\\training.py:33\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m base_layer\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m base_layer_utils\n\u001b[1;32m---> 33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m compile_utils\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m data_adapter\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m input_layer \u001b[38;5;28;01mas\u001b[39;00m input_layer_module\n",
      "File \u001b[1;32mC:\\Users\\Public\\anaconda\\envs\\tf-gpu\\lib\\site-packages\\keras\\engine\\compile_utils.py:24\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m losses \u001b[38;5;28;01mas\u001b[39;00m losses_mod\n\u001b[1;32m---> 24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m metrics \u001b[38;5;28;01mas\u001b[39;00m metrics_mod\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaving\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m saving_lib\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m generic_utils\n",
      "File \u001b[1;32mC:\\Users\\Public\\anaconda\\envs\\tf-gpu\\lib\\site-packages\\keras\\metrics\\__init__.py:33\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase_metric\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m clone_metrics\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# Metric functions\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# Individual metric classes\u001b[39;00m\n\u001b[1;32m---> 33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AUC\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Accuracy\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BinaryAccuracy\n",
      "File \u001b[1;32mC:\\Users\\Public\\anaconda\\envs\\tf-gpu\\lib\\site-packages\\keras\\metrics\\metrics.py:28\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m---> 28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m activations\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m backend\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtensor\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m utils \u001b[38;5;28;01mas\u001b[39;00m dtensor_utils\n",
      "File \u001b[1;32mC:\\Users\\Public\\anaconda\\envs\\tf-gpu\\lib\\site-packages\\keras\\activations.py:21\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mactivation\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mactivation_layers\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m backend\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m generic_utils\n",
      "File \u001b[1;32mC:\\Users\\Public\\anaconda\\envs\\tf-gpu\\lib\\site-packages\\keras\\layers\\__init__.py:20\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase_layer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Layer\n\u001b[1;32m---> 20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase_preprocessing_layer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PreprocessingLayer\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Generic layers.\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minput_layer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Input\n",
      "File \u001b[1;32mC:\\Users\\Public\\anaconda\\envs\\tf-gpu\\lib\\site-packages\\keras\\engine\\base_preprocessing_layer.py:21\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mabc\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m data_adapter\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase_layer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Layer\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m version_utils\n",
      "File \u001b[1;32mC:\\Users\\Public\\anaconda\\envs\\tf-gpu\\lib\\site-packages\\keras\\engine\\data_adapter.py:43\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtf_export\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m keras_export\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 43\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[0;32m     45\u001b[0m     pd \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Users\\Public\\anaconda\\envs\\tf-gpu\\lib\\site-packages\\pandas\\__init__.py:138\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreshape\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m    121\u001b[0m     concat,\n\u001b[0;32m    122\u001b[0m     lreshape,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    134\u001b[0m     qcut,\n\u001b[0;32m    135\u001b[0m )\n\u001b[0;32m    137\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m api, arrays, errors, io, plotting, tseries\n\u001b[1;32m--> 138\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m testing  \u001b[38;5;66;03m# noqa:PDF015\u001b[39;00m\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_print_versions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m show_versions\n\u001b[0;32m    141\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m    142\u001b[0m     \u001b[38;5;66;03m# excel\u001b[39;00m\n\u001b[0;32m    143\u001b[0m     ExcelFile,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    171\u001b[0m     read_spss,\n\u001b[0;32m    172\u001b[0m )\n",
      "File \u001b[1;32mC:\\Users\\Public\\anaconda\\envs\\tf-gpu\\lib\\site-packages\\pandas\\testing.py:6\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;124;03mPublic testing utility functions.\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_testing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      7\u001b[0m     assert_extension_array_equal,\n\u001b[0;32m      8\u001b[0m     assert_frame_equal,\n\u001b[0;32m      9\u001b[0m     assert_index_equal,\n\u001b[0;32m     10\u001b[0m     assert_series_equal,\n\u001b[0;32m     11\u001b[0m )\n\u001b[0;32m     13\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124massert_extension_array_equal\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124massert_frame_equal\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124massert_series_equal\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124massert_index_equal\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     18\u001b[0m ]\n",
      "File \u001b[1;32mC:\\Users\\Public\\anaconda\\envs\\tf-gpu\\lib\\site-packages\\pandas\\_testing\\__init__.py:903\u001b[0m\n\u001b[0;32m    898\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpytest\u001b[39;00m\n\u001b[0;32m    900\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pytest\u001b[38;5;241m.\u001b[39mraises(expected_exception, match\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)  \u001b[38;5;66;03m# noqa: PDF010\u001b[39;00m\n\u001b[1;32m--> 903\u001b[0m cython_table \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcore\u001b[49m\u001b[38;5;241m.\u001b[39mcommon\u001b[38;5;241m.\u001b[39m_cython_table\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m    906\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_cython_table_params\u001b[39m(ndframe, func_names_and_expected):\n\u001b[0;32m    907\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    908\u001b[0m \u001b[38;5;124;03m    Combine frame, functions from com._cython_table\u001b[39;00m\n\u001b[0;32m    909\u001b[0m \u001b[38;5;124;03m    keys and expected result.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    921\u001b[0m \u001b[38;5;124;03m        List of three items (DataFrame, function, expected result)\u001b[39;00m\n\u001b[0;32m    922\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: partially initialized module 'pandas' has no attribute 'core' (most likely due to a circular import)"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import random\n",
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import linregress"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nutritional-yield",
   "metadata": {},
   "source": [
    "## Defining some useful global variables\n",
    "\n",
    "Next you will define some global variables that will be used throughout the assignment.\n",
    "\n",
    "- `EMBEDDING_DIM`: Dimension of the dense embedding, will be used in the embedding layer of the model. Defaults to 100.\n",
    "\n",
    "\n",
    "- `MAXLEN`: Maximum length of all sequences. Defaults to 16.\n",
    "\n",
    "\n",
    "- `TRUNCATING`: Truncating strategy (truncate either before or after each sequence.). Defaults to 'post'.\n",
    "\n",
    "\n",
    "- `PADDING`: Padding strategy (pad either before or after each sequence.). Defaults to 'post'.\n",
    "\n",
    "\n",
    "- `OOV_TOKEN`: Token to replace out-of-vocabulary words during text_to_sequence calls. Defaults to \\\"\\\\<OOV>\\\".\n",
    "    \n",
    "    \n",
    "- `MAX_EXAMPLES`: Max number of examples to use. Defaults to 160000 (10% of the original number of examples)\n",
    "    \n",
    "    \n",
    "- `TRAINING_SPLIT`: Proportion of data used for training. Defaults to 0.9\n",
    "    \n",
    "    \n",
    "**For now leave them unchanged but after submitting your assignment for grading you are encouraged to come back here and play with these parameters to see the impact they have in the classification process.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "occasional-penalty",
   "metadata": {
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 100\n",
    "MAXLEN = 16\n",
    "TRUNCATING = 'post'\n",
    "PADDING = 'post'\n",
    "OOV_TOKEN = \"<OOV>\"\n",
    "MAX_EXAMPLES = 160000\n",
    "TRAINING_SPLIT = 0.9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "applied-rubber",
   "metadata": {},
   "source": [
    "## Explore the dataset\n",
    "\n",
    "The dataset is provided in a csv file. \n",
    "\n",
    "Each row of this file contains the following values separated by commas:\n",
    "\n",
    "- target: the polarity of the tweet (0 = negative, 4 = positive)\n",
    "\n",
    "- ids: The id of the tweet\n",
    "\n",
    "- date: the date of the tweet\n",
    "\n",
    "- flag: The query. If there is no query, then this value is NO_QUERY.\n",
    "\n",
    "- user: the user that tweeted\n",
    "\n",
    "- text: the text of the tweet\n",
    "\n",
    "\n",
    "Take a look at the first two examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "critical-emission",
   "metadata": {
    "tags": [
     "graded"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First data point looks like this:\n",
      "\n",
      "\"0\",\"1467810369\",\"Mon Apr 06 22:19:45 PDT 2009\",\"NO_QUERY\",\"_TheSpecialOne_\",\"@switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D\"\n",
      "\n",
      "Second data point looks like this:\n",
      "\n",
      "\"0\",\"1467810672\",\"Mon Apr 06 22:19:49 PDT 2009\",\"NO_QUERY\",\"scotthamilton\",\"is upset that he can't update his Facebook by texting it... and might cry as a result  School today also. Blah!\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "SENTIMENT_CSV = \"./data/training_cleaned.csv\"\n",
    "\n",
    "with open(SENTIMENT_CSV, 'r') as csvfile:\n",
    "    print(f\"First data point looks like this:\\n\\n{csvfile.readline()}\")\n",
    "    print(f\"Second data point looks like this:\\n\\n{csvfile.readline()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incoming-success",
   "metadata": {},
   "source": [
    "**Notice that this file does not have a header so you won't need to skip the first row when parsing the file.**\n",
    "\n",
    "For the task at hand you will only need the information of the target and the text, which are the first and last element of each row. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sealed-sterling",
   "metadata": {},
   "source": [
    "## Parsing the raw data\n",
    "\n",
    "Now you need to read the data from the csv file. To do so, complete the `parse_data_from_file` function.\n",
    "\n",
    "A couple of things to note:\n",
    "\n",
    "- You should NOT omit the first line as the file does not contain headers.\n",
    "- There is no need to save the data points as numpy arrays, regular lists is fine.\n",
    "- To read from csv files use `csv.reader` by passing the appropriate arguments.\n",
    "- `csv.reader` returns an iterable that returns each row in every iteration. So the label can be accessed via `row[0]` and the text via `row[5]`.\n",
    "- The labels are originally encoded as strings ('0' representing negative and '4' representing positive). **You need to change this so that the labels are integers and 0 is used for representing negative, while 1 should represent positive.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "imperial-scratch",
   "metadata": {
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "def parse_data_from_file(filename):\n",
    "    \"\"\"\n",
    "    Extracts sentences and labels from a CSV file\n",
    "    \n",
    "    Args:\n",
    "        filename (string): path to the CSV file\n",
    "    \n",
    "    Returns:\n",
    "        sentences, labels (list of string, list of string): tuple containing lists of sentences and labels\n",
    "    \"\"\"\n",
    "    \n",
    "    sentences = []\n",
    "    labels = []\n",
    "    \n",
    "    with open(filename, 'r') as csvfile:\n",
    "        ### START CODE HERE\n",
    "        reader = csv.reader(csvfile, delimiter=',')\n",
    "        for row in reader:\n",
    "            sentences.append(row[5])\n",
    "            labels.append(int(row[0] == '4'))\n",
    "            \n",
    "        \n",
    "        \n",
    "        ### END CODE HERE\n",
    "        \n",
    "    return sentences, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "banned-medicare",
   "metadata": {
    "tags": [
     "graded"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset contains 1600000 examples\n",
      "\n",
      "Text of second example should look like this:\n",
      "is upset that he can't update his Facebook by texting it... and might cry as a result  School today also. Blah!\n",
      "\n",
      "Text of fourth example should look like this:\n",
      "my whole body feels itchy and like its on fire \n",
      "\n",
      "Labels of last 5 examples should look like this:\n",
      "[1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "# Test your function\n",
    "sentences, labels = parse_data_from_file(SENTIMENT_CSV)\n",
    "\n",
    "print(f\"dataset contains {len(sentences)} examples\\n\")\n",
    "\n",
    "print(f\"Text of second example should look like this:\\n{sentences[1]}\\n\")\n",
    "print(f\"Text of fourth example should look like this:\\n{sentences[3]}\")\n",
    "\n",
    "print(f\"\\nLabels of last 5 examples should look like this:\\n{labels[-5:]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "confidential-delay",
   "metadata": {},
   "source": [
    "***Expected Output:***\n",
    "\n",
    "```\n",
    "dataset contains 1600000 examples\n",
    "\n",
    "Text of second example should look like this:\n",
    "is upset that he can't update his Facebook by texting it... and might cry as a result  School today also. Blah!\n",
    "\n",
    "Text of fourth example should look like this:\n",
    "my whole body feels itchy and like its on fire \n",
    "\n",
    "Labels of last 5 examples should look like this:\n",
    "[1, 1, 1, 1, 1]\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "residential-tonight",
   "metadata": {},
   "source": [
    "You might have noticed that this dataset contains a lot of examples. In order to keep a low execution time of this assignment you will be using only 10% of the original data. The next cell does this while also randomnizing the datapoints that will be used:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "framed-holmes",
   "metadata": {
    "tags": [
     "graded"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 160000 sentences and 160000 labels after random sampling\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Bundle the two lists into a single one\n",
    "sentences_and_labels = list(zip(sentences, labels))\n",
    "\n",
    "# Perform random sampling\n",
    "random.seed(42)\n",
    "sentences_and_labels = random.sample(sentences_and_labels, MAX_EXAMPLES)\n",
    "\n",
    "# Unpack back into separate lists\n",
    "sentences, labels = zip(*sentences_and_labels)\n",
    "\n",
    "print(f\"There are {len(sentences)} sentences and {len(labels)} labels after random sampling\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "guilty-denial",
   "metadata": {},
   "source": [
    "***Expected Output:***\n",
    "\n",
    "```\n",
    "There are 160000 sentences and 160000 labels after random sampling\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "contained-bridge",
   "metadata": {},
   "source": [
    "## Training - Validation Split\n",
    "\n",
    "Now you will code the `train_val_split`, which given the list of sentences, the list of labels and the proportion of data for the training set, should return the training and validation sentences and labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "elegant-medicare",
   "metadata": {
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "def train_val_split(sentences, labels, training_split):\n",
    "    \"\"\"\n",
    "    Splits the dataset into training and validation sets\n",
    "    \n",
    "    Args:\n",
    "        sentences (list of string): lower-cased sentences without stopwords\n",
    "        labels (list of string): list of labels\n",
    "        training split (float): proportion of the dataset to convert to include in the train set\n",
    "    \n",
    "    Returns:\n",
    "        train_sentences, validation_sentences, train_labels, validation_labels - lists containing the data splits\n",
    "    \"\"\"    \n",
    "    ### START CODE HERE\n",
    "    \n",
    "    # Compute the number of sentences that will be used for training (should be an integer)\n",
    "    train_size = int(len(sentences) * training_split)\n",
    "\n",
    "    # Split the sentences and labels into train/validation splits\n",
    "    train_sentences = sentences[:train_size]\n",
    "    train_labels = labels[:train_size]\n",
    "\n",
    "    validation_sentences = sentences[train_size:]\n",
    "    validation_labels = labels[train_size:]\n",
    "    \n",
    "    ### END CODE HERE\n",
    "    \n",
    "    return train_sentences, validation_sentences, train_labels, validation_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "green-finding",
   "metadata": {
    "tags": [
     "graded"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 144000 sentences for training.\n",
      "\n",
      "There are 144000 labels for training.\n",
      "\n",
      "There are 16000 sentences for validation.\n",
      "\n",
      "There are 16000 labels for validation.\n"
     ]
    }
   ],
   "source": [
    "# Test your function\n",
    "train_sentences, val_sentences, train_labels, val_labels = train_val_split(sentences, labels, TRAINING_SPLIT)\n",
    "\n",
    "print(f\"There are {len(train_sentences)} sentences for training.\\n\")\n",
    "print(f\"There are {len(train_labels)} labels for training.\\n\")\n",
    "print(f\"There are {len(val_sentences)} sentences for validation.\\n\")\n",
    "print(f\"There are {len(val_labels)} labels for validation.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imperial-bangkok",
   "metadata": {},
   "source": [
    "***Expected Output:***\n",
    "\n",
    "```\n",
    "There are 144000 sentences for training.\n",
    "\n",
    "There are 144000 labels for training.\n",
    "\n",
    "There are 16000 sentences for validation.\n",
    "\n",
    "There are 16000 labels for validation.\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wired-fifteen",
   "metadata": {},
   "source": [
    "## Tokenization - Sequences, truncating and padding\n",
    "\n",
    "Now that you have sets for training and validation it is time for you to begin the tokenization process.\n",
    "\n",
    "Begin by completing the `fit_tokenizer` function below. This function should return a [Tokenizer](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/text/Tokenizer) that has been fitted to the training sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "atmospheric-shakespeare",
   "metadata": {
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "def fit_tokenizer(train_sentences, oov_token):\n",
    "    \"\"\"\n",
    "    Instantiates the Tokenizer class on the training sentences\n",
    "    \n",
    "    Args:\n",
    "        train_sentences (list of string): lower-cased sentences without stopwords to be used for training\n",
    "        oov_token (string) - symbol for the out-of-vocabulary token\n",
    "    \n",
    "    Returns:\n",
    "        tokenizer (object): an instance of the Tokenizer class containing the word-index dictionary\n",
    "    \"\"\"\n",
    "    ### START CODE HERE\n",
    "    \n",
    "    # Instantiate the Tokenizer class, passing in the correct value for oov_token\n",
    "    tokenizer = Tokenizer(oov_token=oov_token)\n",
    "    \n",
    "    # Fit the tokenizer to the training sentences\n",
    "    tokenizer.fit_on_texts(train_sentences)\n",
    "    \n",
    "    ### END CODE HERE\n",
    "    \n",
    "    return tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "included-entertainment",
   "metadata": {
    "tags": [
     "graded"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary contains 128293 words\n",
      "\n",
      "<OOV> token included in vocabulary\n",
      "\n",
      "index of word 'i' should be 2\n"
     ]
    }
   ],
   "source": [
    "# Test your function\n",
    "tokenizer = fit_tokenizer(train_sentences, OOV_TOKEN)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "VOCAB_SIZE = len(word_index)\n",
    "\n",
    "print(f\"Vocabulary contains {VOCAB_SIZE} words\\n\")\n",
    "print(\"<OOV> token included in vocabulary\" if \"<OOV>\" in word_index else \"<OOV> token NOT included in vocabulary\")\n",
    "print(f\"\\nindex of word 'i' should be {word_index['i']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "covered-williams",
   "metadata": {},
   "source": [
    "***Expected Output:***\n",
    "\n",
    "```\n",
    "Vocabulary contains 128293 words\n",
    "\n",
    "<OOV> token included in vocabulary\n",
    "\n",
    "index of word 'i' should be 2\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "attractive-cooper",
   "metadata": {
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "def seq_pad_and_trunc(sentences, tokenizer, padding, truncating, maxlen):\n",
    "    \"\"\"\n",
    "    Generates an array of token sequences and pads them to the same length\n",
    "    \n",
    "    Args:\n",
    "        sentences (list of string): list of sentences to tokenize and pad\n",
    "        tokenizer (object): Tokenizer instance containing the word-index dictionary\n",
    "        padding (string): type of padding to use\n",
    "        truncating (string): type of truncating to use\n",
    "        maxlen (int): maximum length of the token sequence\n",
    "    \n",
    "    Returns:\n",
    "        pad_trunc_sequences (array of int): tokenized sentences padded to the same length\n",
    "    \"\"\"        \n",
    "    ### START CODE HERE\n",
    "       \n",
    "    # Convert sentences to sequences\n",
    "    sequences = tokenizer.texts_to_sequences(sentences)\n",
    "    \n",
    "    # Pad the sequences using the correct padding, truncating and maxlen\n",
    "    pad_trunc_sequences = pad_sequences(sequences, padding=padding, truncating=truncating, maxlen=maxlen)\n",
    "    \n",
    "    ### END CODE HERE\n",
    "    \n",
    "    return pad_trunc_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "extra-mention",
   "metadata": {
    "tags": [
     "graded"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Padded and truncated training sequences have shape: (144000, 16)\n",
      "\n",
      "Padded and truncated validation sequences have shape: (16000, 16)\n"
     ]
    }
   ],
   "source": [
    "# Test your function\n",
    "train_pad_trunc_seq = seq_pad_and_trunc(train_sentences, tokenizer, PADDING, TRUNCATING, MAXLEN)\n",
    "val_pad_trunc_seq = seq_pad_and_trunc(val_sentences, tokenizer, PADDING, TRUNCATING, MAXLEN)\n",
    "\n",
    "print(f\"Padded and truncated training sequences have shape: {train_pad_trunc_seq.shape}\\n\")\n",
    "print(f\"Padded and truncated validation sequences have shape: {val_pad_trunc_seq.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "posted-stockholm",
   "metadata": {},
   "source": [
    "***Expected Output:***\n",
    "\n",
    "```\n",
    "Padded and truncated training sequences have shape: (144000, 16)\n",
    "\n",
    "Padded and truncated validation sequences have shape: (16000, 16)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "least-rough",
   "metadata": {},
   "source": [
    "Remember that the `pad_sequences` function returns numpy arrays, so your training and validation sequences are already in this format.\n",
    "\n",
    "However the labels are still Python lists. Before going forward you should convert them numpy arrays as well. You can do this by running the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "studied-minneapolis",
   "metadata": {
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "train_labels = np.array(train_labels)\n",
    "val_labels = np.array(val_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "corresponding-choir",
   "metadata": {},
   "source": [
    "# Using pre-defined Embeddings\n",
    "\n",
    "This time you will not be learning embeddings from your data but you will be using pre-trained word vectors.\n",
    "\n",
    "In particular you will be using the 100 dimension version of [GloVe](https://nlp.stanford.edu/projects/glove/) from Stanford."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "continental-pittsburgh",
   "metadata": {
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "# Define path to file containing the embeddings\n",
    "GLOVE_FILE = './data/glove.6B.100d.txt'\n",
    "\n",
    "# Initialize an empty embeddings index dictionary\n",
    "GLOVE_EMBEDDINGS = {}\n",
    "\n",
    "# Read file and fill GLOVE_EMBEDDINGS with its contents\n",
    "with open(GLOVE_FILE) as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        GLOVE_EMBEDDINGS[word] = coefs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "varied-furniture",
   "metadata": {},
   "source": [
    "Now you have access to GloVe's pre-trained word vectors. Isn't that cool?\n",
    "\n",
    "Let's take a look at the vector for the word **dog**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "awful-mouse",
   "metadata": {
    "tags": [
     "graded"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector representation of word dog looks like this:\n",
      "\n",
      "[ 0.30817    0.30938    0.52803   -0.92543   -0.73671    0.63475\n",
      "  0.44197    0.10262   -0.09142   -0.56607   -0.5327     0.2013\n",
      "  0.7704    -0.13983    0.13727    1.1128     0.89301   -0.17869\n",
      " -0.0019722  0.57289    0.59479    0.50428   -0.28991   -1.3491\n",
      "  0.42756    1.2748    -1.1613    -0.41084    0.042804   0.54866\n",
      "  0.18897    0.3759     0.58035    0.66975    0.81156    0.93864\n",
      " -0.51005   -0.070079   0.82819   -0.35346    0.21086   -0.24412\n",
      " -0.16554   -0.78358   -0.48482    0.38968   -0.86356   -0.016391\n",
      "  0.31984   -0.49246   -0.069363   0.018869  -0.098286   1.3126\n",
      " -0.12116   -1.2399    -0.091429   0.35294    0.64645    0.089642\n",
      "  0.70294    1.1244     0.38639    0.52084    0.98787    0.79952\n",
      " -0.34625    0.14095    0.80167    0.20987   -0.86007   -0.15308\n",
      "  0.074523   0.40816    0.019208   0.51587   -0.34428   -0.24525\n",
      " -0.77984    0.27425    0.22418    0.20164    0.017431  -0.014697\n",
      " -1.0235    -0.39695   -0.0056188  0.30569    0.31748    0.021404\n",
      "  0.11837   -0.11319    0.42456    0.53405   -0.16717   -0.27185\n",
      " -0.6255     0.12883    0.62529   -0.52086  ]\n"
     ]
    }
   ],
   "source": [
    "test_word = 'dog'\n",
    "\n",
    "test_vector = GLOVE_EMBEDDINGS[test_word]\n",
    "\n",
    "print(f\"Vector representation of word {test_word} looks like this:\\n\\n{test_vector}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "persistent-tolerance",
   "metadata": {},
   "source": [
    "Feel free to change the `test_word` to see the vector representation of any word you can think of.\n",
    "\n",
    "Also, notice that the dimension of each vector is 100. You can easily double check this by running the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "published-surgery",
   "metadata": {
    "tags": [
     "graded"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Each word vector has shape: (100,)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Each word vector has shape: {test_vector.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "handy-chuck",
   "metadata": {},
   "source": [
    "## Represent the words in your vocabulary using the embeddings\n",
    "\n",
    "Save the vector representation of each word in the vocabulary in a numpy array.\n",
    "\n",
    "A couple of things to notice:\n",
    "- If a word in your vocabulary is not present in `GLOVE_EMBEDDINGS` the representation for that word is left as a column of zeros.\n",
    "- `word_index` starts counting at 1, because of this you will need to add an extra column at the left-most side of the `EMBEDDINGS_MATRIX` array. This is the reason why you add 1 to `VOCAB_SIZE` in the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "crazy-process",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C1zdgJkusRh0",
    "outputId": "538df576-bbfc-4590-c3a3-0559dab5f176",
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "# Initialize an empty numpy array with the appropriate size\n",
    "EMBEDDINGS_MATRIX = np.zeros((VOCAB_SIZE+1, EMBEDDING_DIM))\n",
    "\n",
    "# Iterate all of the words in the vocabulary and if the vector representation for \n",
    "# each word exists within GloVe's representations, save it in the EMBEDDINGS_MATRIX array\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = GLOVE_EMBEDDINGS.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        EMBEDDINGS_MATRIX[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "otherwise-chester",
   "metadata": {},
   "source": [
    "Now you have the pre-trained embeddings ready to use!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "missing-solution",
   "metadata": {},
   "source": [
    "## Define a model that does not overfit\n",
    "\n",
    "Now you need to define a model that will handle the problem at hand while not overfitting.\n",
    "\n",
    "A couple of things to note / hints:\n",
    "\n",
    "- The first layer is provided so you can see how the Embedding layer is configured when using pre-trained embeddings\n",
    "\n",
    "\n",
    "- You can try different combinations of layers covered in previous ungraded labs such as:\n",
    "    - `Conv1D`\n",
    "    - `Dropout`\n",
    "    - `GlobalMaxPooling1D`    \n",
    "    - `MaxPooling1D`    \n",
    "    - `LSTM`    \n",
    "    - `Bidirectional(LSTM)`\n",
    "\n",
    "\n",
    "- The last two layers should be `Dense` layers.\n",
    "\n",
    "\n",
    "- There multiple ways of solving this problem. So try an architecture that you think will not overfit.\n",
    "\n",
    "\n",
    "- Try simpler architectures first to avoid long training times. Architectures that are able to solve this problem usually have around 3-4 layers (excluding the last two `Dense` ones)\n",
    "\n",
    "\n",
    "- Include at least one `Dropout` layer to mitigate overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "representative-taylor",
   "metadata": {
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: create_model\n",
    "def create_model(vocab_size, embedding_dim, maxlen, embeddings_matrix):\n",
    "    \"\"\"\n",
    "    Creates a binary sentiment classifier model\n",
    "    \n",
    "    Args:\n",
    "        vocab_size (int): size of the vocabulary for the Embedding layer input\n",
    "        embedding_dim (int): dimensionality of the Embedding layer output\n",
    "        maxlen (int): length of the input sequences\n",
    "        embeddings_matrix (array): predefined weights of the embeddings\n",
    "    \n",
    "    Returns:\n",
    "        model (tf.keras Model): the sentiment classifier model\n",
    "    \"\"\"\n",
    "    ### START CODE HERE\n",
    "    \n",
    "    model = tf.keras.Sequential([ \n",
    "        # This is how you need to set the Embedding layer when using pre-trained embeddings\n",
    "        tf.keras.layers.Embedding(vocab_size+1, embedding_dim, input_length=maxlen, weights=[embeddings_matrix], trainable=False),\n",
    "        tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(300)),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(512, 'relu'),\n",
    "        tf.keras.layers.Dropout(0.8),\n",
    "        tf.keras.layers.Dense(1, 'sigmoid'),\n",
    "    ])\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy', \n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy']) \n",
    "\n",
    "    ### END CODE HERE\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "explicit-tokyo",
   "metadata": {
    "tags": [
     "graded"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_6 (Embedding)     (None, 16, 100)           12829400  \n",
      "                                                                 \n",
      " bidirectional_8 (Bidirectio  (None, 64)               34048     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12,863,513\n",
      "Trainable params: 34,113\n",
      "Non-trainable params: 12,829,400\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "4500/4500 [==============================] - 69s 15ms/step - loss: 0.5361 - accuracy: 0.7244 - val_loss: 0.5041 - val_accuracy: 0.7492\n",
      "Epoch 2/20\n",
      "4500/4500 [==============================] - 65s 14ms/step - loss: 0.4899 - accuracy: 0.7597 - val_loss: 0.4852 - val_accuracy: 0.7614\n",
      "Epoch 3/20\n",
      "4500/4500 [==============================] - 59s 13ms/step - loss: 0.4695 - accuracy: 0.7734 - val_loss: 0.4826 - val_accuracy: 0.7638\n",
      "Epoch 4/20\n",
      "4500/4500 [==============================] - 59s 13ms/step - loss: 0.4543 - accuracy: 0.7828 - val_loss: 0.4815 - val_accuracy: 0.7655\n",
      "Epoch 5/20\n",
      "4500/4500 [==============================] - 57s 13ms/step - loss: 0.4419 - accuracy: 0.7902 - val_loss: 0.4775 - val_accuracy: 0.7677\n",
      "Epoch 6/20\n",
      "4500/4500 [==============================] - 58s 13ms/step - loss: 0.4304 - accuracy: 0.7973 - val_loss: 0.4712 - val_accuracy: 0.7707\n",
      "Epoch 7/20\n",
      "4500/4500 [==============================] - 56s 13ms/step - loss: 0.4204 - accuracy: 0.8020 - val_loss: 0.4783 - val_accuracy: 0.7683\n",
      "Epoch 8/20\n",
      "4500/4500 [==============================] - 58s 13ms/step - loss: 0.4099 - accuracy: 0.8093 - val_loss: 0.4888 - val_accuracy: 0.7641\n",
      "Epoch 9/20\n",
      "4500/4500 [==============================] - 58s 13ms/step - loss: 0.4008 - accuracy: 0.8137 - val_loss: 0.4819 - val_accuracy: 0.7676\n",
      "Epoch 10/20\n",
      "4500/4500 [==============================] - 59s 13ms/step - loss: 0.3922 - accuracy: 0.8196 - val_loss: 0.4875 - val_accuracy: 0.7671\n",
      "Epoch 11/20\n",
      "4500/4500 [==============================] - 57s 13ms/step - loss: 0.3841 - accuracy: 0.8238 - val_loss: 0.5058 - val_accuracy: 0.7639\n",
      "Epoch 12/20\n",
      "4500/4500 [==============================] - 57s 13ms/step - loss: 0.3759 - accuracy: 0.8285 - val_loss: 0.4985 - val_accuracy: 0.7659\n",
      "Epoch 13/20\n",
      "4500/4500 [==============================] - 57s 13ms/step - loss: 0.3684 - accuracy: 0.8324 - val_loss: 0.5042 - val_accuracy: 0.7649\n",
      "Epoch 14/20\n",
      "4500/4500 [==============================] - 56s 13ms/step - loss: 0.3617 - accuracy: 0.8361 - val_loss: 0.5103 - val_accuracy: 0.7629\n",
      "Epoch 15/20\n",
      "4500/4500 [==============================] - 57s 13ms/step - loss: 0.3546 - accuracy: 0.8407 - val_loss: 0.5164 - val_accuracy: 0.7623\n",
      "Epoch 16/20\n",
      "4500/4500 [==============================] - 58s 13ms/step - loss: 0.3484 - accuracy: 0.8437 - val_loss: 0.5285 - val_accuracy: 0.7596\n",
      "Epoch 17/20\n",
      "4500/4500 [==============================] - 58s 13ms/step - loss: 0.3420 - accuracy: 0.8469 - val_loss: 0.5406 - val_accuracy: 0.7579\n",
      "Epoch 18/20\n",
      "2479/4500 [===============>..............] - ETA: 24s - loss: 0.3312 - accuracy: 0.8537"
     ]
    }
   ],
   "source": [
    "# Create your untrained model\n",
    "model = create_model(VOCAB_SIZE, EMBEDDING_DIM, MAXLEN, EMBEDDINGS_MATRIX)\n",
    "model.summary()\n",
    "\n",
    "# Train the model and save the training history\n",
    "history = model.fit(train_pad_trunc_seq, train_labels, epochs=20, validation_data=(val_pad_trunc_seq, val_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "local-headquarters",
   "metadata": {},
   "source": [
    "**To pass this assignment your `val_loss` (validation loss) should either be flat or decreasing.** \n",
    "\n",
    "Although a flat `val_loss` and a lowering `train_loss` (or just `loss`) also indicate some overfitting what you really want to avoid is having a lowering `train_loss` and an increasing `val_loss`.\n",
    "\n",
    "With this in mind, the following three curves will be acceptable solutions:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "single-studio",
   "metadata": {},
   "source": [
    "<table><tr><td><img src='images/valid-1.png'></td><td><img src='images/valid-2.jpg'></td><td><img src='images/valid-3.jpg'></td></tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eligible-unknown",
   "metadata": {},
   "source": [
    "While the following would not be able to pass the grading:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "productive-slave",
   "metadata": {},
   "source": [
    "<table><tr><td><img src='images/invalid-1.jpg'></td></tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "helpful-tractor",
   "metadata": {},
   "source": [
    "Run the following cell to check your loss curves:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "golden-stretch",
   "metadata": {
    "tags": [
     "graded"
    ]
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deZzN9f7A8dfb2IqhEZUsWRqV7CaSJD9dlC6ljdum9dKeUm5FUlrVdZXSRt22SXWTFlQiWsiQpbGUZWRJMfaQ7f374/0djnFmnDFz5szyfj4e38ec893Oe87MnPd8dlFVnHPOucxKxDoA55xzBZMnCOecc2F5gnDOOReWJwjnnHNheYJwzjkXlicI55xzYXmCcPlCRMaJyNV5fW4siUiaiJwThfuqiJwYPB4hIv0jOfcwXudyEfn8cOPM5r5ni8jKvL6vy38lYx2AK7hEZGvI0yOBv4A9wfN/qupbkd5LVc+NxrlFnar2yov7iEgtYBlQSlV3B/d+C4j4Z+iKH08QLkuqWj7jsYikAder6peZzxORkhkfOs65osOrmFyOZVQhiMi9IrIGGCUiCSLyiYisFZENwePqIddMFpHrg8c9ReQbERkSnLtMRM49zHNri8gUEdkiIl+KyHAReTOLuCOJ8WER+Ta43+ciUjnk+JUislxE0kXk/mzen5YiskZE4kL2XSgic4PHLUTkexHZKCK/ichzIlI6i3u9JiKPhDzvG1yzWkSuzXRuZxH5UUQ2i8gKERkYcnhK8HWjiGwVkVYZ723I9WeIyAwR2RR8PSPS9yY7InJKcP1GEUkVkS4hx84TkfnBPVeJyN3B/srBz2ejiKwXkaki4p9X+czfcHe4jgMqAScAN2K/S6OC5zWB7cBz2VzfElgEVAaeBF4VETmMc98GfgCOBgYCV2bzmpHE+A/gGuAYoDSQ8YFVH3ghuP/xwetVJwxVnQ78Cfxfpvu+HTzeA9wZfD+tgPbATdnETRBDpyCevwGJQOb2jz+Bq4CjgM5AbxG5IDh2VvD1KFUtr6rfZ7p3JeBTYFjwvT0DfCoiR2f6Hg56bw4RcyngY+Dz4LpbgbdE5KTglFex6sp4oAHwVbD/LmAlUAU4FrgP8HmB8pknCHe49gIPqupfqrpdVdNV9QNV3aaqW4DBQNtsrl+uqi+r6h7gdaAq9kEQ8bkiUhM4DRigqjtV9RtgbFYvGGGMo1T1Z1XdDowGmgT7LwY+UdUpqvoX0D94D7LyDtADQETigfOCfajqTFWdpqq7VTUNeDFMHOFcGsT3k6r+iSXE0O9vsqrOU9W9qjo3eL1I7guWUH5R1TeCuN4BFgJ/Dzknq/cmO6cD5YHHg5/RV8AnBO8NsAuoLyIVVHWDqs4K2V8VOEFVd6nqVPWJ4/KdJwh3uNaq6o6MJyJypIi8GFTBbMaqNI4KrWbJZE3GA1XdFjwsn8NzjwfWh+wDWJFVwBHGuCbk8baQmI4PvXfwAZ2e1WthpYVuIlIG6AbMUtXlQRz1guqTNUEcj2KliUM5IAZgeabvr6WITAqq0DYBvSK8b8a9l2fatxyoFvI8q/fmkDGramgyDb3vRVjyXC4iX4tIq2D/U8Bi4HMRWSoi/SL7Nlxe8gThDlfm/+buAk4CWqpqBfZXaWRVbZQXfgMqiciRIftqZHN+bmL8LfTewWsendXJqjof+yA8lwOrl8CqqhYCiUEc9x1ODFg1Wai3sRJUDVWtCIwIue+h/vtejVW9haoJrIogrkPdt0am9oN991XVGaraFat+GoOVTFDVLap6l6rWAboAfUSkfS5jcTnkCcLllXisTn9jUJ/9YLRfMPiPPAUYKCKlg/8+/57NJbmJ8X3gfBE5M2hQHsSh/37eBm7HEtF7meLYDGwVkZOB3hHGMBroKSL1gwSVOf54rES1Q0RaYIkpw1qsSqxOFvf+DKgnIv8QkZIichlQH6sOyo3pWGnjHhEpJSJnYz+j5OBndrmIVFTVXdh7shdARM4XkRODtqZNWLtNdlV6Lgo8Qbi8MhQ4AlgHTAPG59PrXo419KYDjwDvYuM1wjnsGFU1FbgZ+9D/DdiANaJmJ6MN4CtVXRey/27sw3sL8HIQcyQxjAu+h6+w6pevMp1yEzBIRLYAAwj+Gw+u3Ya1uXwb9Aw6PdO904HzsVJWOnAPcH6muHNMVXdiCeFc7H1/HrhKVRcGp1wJpAVVbb2wnydYI/yXwFbge+B5VZ2Um1hczom3+7iiRETeBRaqatRLMM4VdV6CcIWaiJwmInVFpETQDbQrVpftnMslH0ntCrvjgP9hDcYrgd6q+mNsQ3KuaPAqJuecc2F5FZNzzrmwikwVU+XKlbVWrVqxDsM55wqVmTNnrlPVKuGOFZkEUatWLVJSUmIdhnPOFSoiknkE/T5exeSccy4sTxDOOefC8gThnHMurCLTBhHOrl27WLlyJTt27Dj0ya7AKFu2LNWrV6dUqVKxDsW5Yq1IJ4iVK1cSHx9PrVq1yHotGleQqCrp6emsXLmS2rVrxzoc54q1Il3FtGPHDo4++mhPDoWIiHD00Ud7qc+5AqBIJwjAk0Mh5D8z5wqGIl3F5JxzBdnatfDJJ/Drr1C2LBxxhH3N7nG453FZrduYS54goqx8+fJs3bo11mE45wqIpUthzBjbvv0W9ubBMkitWsF33+X+Ppl5gnDOuShShdmz4cMPLSnMm2f7GzeG/v3hggugYUP46y/YscO27dv3P47k+bHHRid2TxAxMHv2bHr16sW2bduoW7cuI0eOJCEhgWHDhjFixAhKlixJ/fr1SU5O5uuvv+b2228HrG5+ypQpxMfHx/g7cM5lZ/dumDp1f0nh11+hRAk480x45hlLCpk76R15pG0FSfFJEHfcYWk8LzVpAkOH5viyq666imeffZa2bdsyYMAAHnroIYYOHcrjjz/OsmXLKFOmDBs3bgRgyJAhDB8+nNatW7N161bKli2bt9+Dcy5P/PknfP65JYRPPoH16619oEMHGDgQzj8fqoSdEq/gKvK9mAqaTZs2sXHjRtq2bQvA1VdfzZQpUwBo1KgRl19+OW+++SYlS1rubt26NX369GHYsGFs3Lhx337nXMEwYYKVCKpUgW7d4OOPoXNn+N//YN06+OgjuOaawpccoDiVIA7jP/389umnnzJlyhQ+/vhjBg8ezLx58+jXrx+dO3fms88+o3Xr1kyYMIGTTz451qE6V+ypwqOPwgMPQLVqcP31lijatIGiMglA8UkQBUTFihVJSEhg6tSptGnThjfeeIO2bduyd+9eVqxYQbt27TjzzDNJTk5m69atpKen07BhQxo2bMiMGTNYuHChJwjnYmzHDksIb70F//gHvPqqVScVNZ4gomzbtm1Ur1593/M+ffrw+uuv72ukrlOnDqNGjWLPnj1cccUVbNq0CVXltttu46ijjqJ///5MmjSJEiVKcOqpp3LuuefG8Ltxzq1ZYyWF6dNh8GD417+gqI7t9AQRZXuz6OQ8bdq0g/Z98803B+179tln8zwm59zhmT0bunSB9HT44ANrcyjKvJHaOeci8OGH0Lq1tT18803RTw7gCcI557KV0RjdrZsNaJsxA5o2jXVU+SOqCUJEOonIIhFZLCL9sjjnUhGZLyKpIvJ2yP6rReSXYLs6mnE651w4O3bAlVfC/fdbY/TkyXDccbGOKv9ErQ1CROKA4cDfgJXADBEZq6rzQ85JBP4FtFbVDSJyTLC/EvAgkAQoMDO4dkO04nXOuVDFqTE6K9EsQbQAFqvqUlXdCSQDXTOdcwMwPOODX1X/CPZ3BL5Q1fXBsS+ATlGM1Tnn9pk9G1q0sHmTPvgA7ruv+CUHiG6CqAasCHm+MtgXqh5QT0S+FZFpItIpB9ciIjeKSIqIpKxduzYPQ3fOFVfFsTE6K7FupC4JJAJnAz2Al0XkqEgvVtWXVDVJVZOqFMBx7O3atWPChAkH7Bs6dCi9e/fO8pqzzz6blJQUAM4777x9czKFGjhwIEOGDMn2tceMGcP8+ftq8xgwYABffvllTsIPa/LkyZx//vm5vo9zBU1xbozOSjQTxCqgRsjz6sG+UCuBsaq6S1WXAT9jCSOSawu8Hj16kJycfMC+5ORkevToEdH1n332GUcdFXG+PEDmBDFo0CDOOeecw7qXc0VdcW+Mzko0E8QMIFFEaotIaaA7MDbTOWOw0gMiUhmrcloKTAA6iEiCiCQAHYJ9hcrFF1/Mp59+ys6dOwFIS0tj9erVtGnTht69e5OUlMSpp57Kgw8+GPb6WrVqsW7dOgAGDx5MvXr1OPPMM1m0aNG+c15++WVOO+00GjduzEUXXcS2bdv47rvvGDt2LH379qVJkyYsWbKEnj178v777wMwceJEmjZtSsOGDbn22mv566+/9r3egw8+SLNmzWjYsCELFy6M+Ht95513aNiwIQ0aNODee+8FYM+ePfTs2ZMGDRrQsGFD/v3vfwMwbNgw6tevT6NGjejevXsO31Xn8taaNdCunU2bMXgwvPlm0Zw243BErReTqu4WkVuwD/Y4YKSqporIICBFVceyPxHMB/YAfVU1HUBEHsaSDMAgVV2fm3hiMdt3pUqVaNGiBePGjaNr164kJydz6aWXIiIMHjyYSpUqsWfPHtq3b8/cuXNp1KhR2PvMnDmT5ORkZs+eze7du2nWrBnNmzcHoFu3btxwww0APPDAA7z66qvceuutdOnShfPPP5+LL774gHvt2LGDnj17MnHiROrVq8dVV13FCy+8wB133AFA5cqVmTVrFs8//zxDhgzhlVdeOeT7sHr1au69915mzpxJQkICHTp0YMyYMdSoUYNVq1bx008/AeyrLgs3rblzsbBoEXTsaEt/FoeR0TkV1TYIVf1MVeupal1VHRzsGxAkB9T0UdX6qtpQVZNDrh2pqicG26hoxhlNodVModVLo0ePplmzZjRt2pTU1NQDqoMymzp1KhdeeCFHHnkkFSpUoEuXLvuO/fTTT7Rp04aGDRvy1ltvkZqamm08ixYtonbt2tSrVw84cLpxsIQD0Lx5c9LS0iL6HmfMmMHZZ59NlSpVKFmyJJdffjlTpkyhTp06LF26lFtvvZXx48dToUIFIPy05s7lt+nTrTF6+3aYMsWTQzjF5q8zVrN9d+3alTvvvJNZs2axbds2mjdvzrJlyxgyZAgzZswgISGBnj17smPHjsO6f8+ePRkzZgyNGzfmtddeY/LkybmKt0yZMgDExcWxe/fuXN0rISGBOXPmMGHCBEaMGMHo0aMZOXJk2GnNPVG4/DRuHFx8sbUzfP451K0b64gKplj3YiryypcvT7t27bj22mv3lR42b95MuXLlqFixIr///jvjxo3L9h5nnXUWY8aMYfv27WzZsoWPP/5437EtW7ZQtWpVdu3axVtvvbVvf3x8PFu2bDnoXieddBJpaWksXrwYYN9047nRokULvv76a9atW8eePXt45513aNu2LevWrWPv3r1cdNFFPPLII8yaNeuAac2feOIJNm3axNatW3P1+s7lxH//axPunXQSfPedJ4fs+L9t+aBHjx5ceOGF+6qaGjduTNOmTTn55JOpUaMGrVu3zvb6Zs2acdlll9G4cWOOOeYYTjvttH3HHn74YVq2bEmVKlVo2bLlvqTQvXt3brjhBoYNG7avcRqgbNmyjBo1iksuuYTdu3dz2mmn0atXrxx9PxMnTjxgCvP33nuPxx9/nHbt2qGqdO7cma5duzJnzhyuueaafTPaPvbYY1lOa+5cfhgyBPr2hfbtbcW3oNbTZUFUNdYx5ImkpCTNGD+QYcGCBZxyyikxisjlhv/sXF7au9cSwzPPwKWXWikiqE0t9kRkpqomhTvmJQjnXJG2c6etCf3223DbbfDvf0MJr1yPiCcI51yRtWWLNUZ//jk89hjce2/xnFPpcBX5BKGqiP9GFCpFpdrTxdYff0DnzvDjjzBypJUiXM4U6YJW2bJlSU9P9w+cQkRVSU9Pp6wPZXW5sHSpjXFITYUxYzw5HK4iXYKoXr06K1euxGd6LVzKli17QC8p53Ji9mzo1MnaHiZOhFatYh1R4VWkE0SpUqWoXbt2rMNwzuWTSZOga1eoWBG++grq1491RIVbka5ics4VH++9ZyWHmjXh++89OeQFTxDOuUJv+HC47DI47TSYOhW8hjJvFOkqJudc0aEK6emwciWsWrX/6/z5NhNrly6QnAxHHBHrSIsOTxDOuZjbs8fWZQj98A/3OFi6ZJ8SJaBqVbj9dptGw+d8zFv+djrnYmb3bpv6YuxYSxKhSpe2qqJq1aBly/2Pq1ff//i44zwpRJO/tc65mOnfHz78EG66CRo12p8AqlWDypV91HOseYJwzsXEJ5/A44/DjTdaI7MreLwXk3Mu36WlwVVXQdOm8J//xDoalxVPEM65fPXXX9busHevjV3wWVUKrqgmCBHpJCKLRGSxiPQLc7yniKwVkdnBdn3IsT0h+8dGM05WroRdu6L6Es45c/fdMGMGjBrlq7kVdFFLECISBwwHzgXqAz1EJNzYxndVtUmwvRKyf3vI/i7RipOff4bERHjppai9hHPOvPsuPPcc9OkDF14Y62jcoUSzBNECWKyqS1V1J5AMdI3i6x2exESbzWvgQNi0KdbROFdkLVoE118PZ5xhjdOu4ItmgqgGrAh5vjLYl9lFIjJXRN4XkRoh+8uKSIqITBORC8K9gIjcGJyTctgztorYCJv0dFtRxDmX57Zts4V7ypa1UkSpUrGOyEUi1o3UHwO1VLUR8AXwesixE4J1Uv8BDBWRg2orVfUlVU1S1aQqVaocfhTNmsGVV8LQobB8+eHfxzkX1s0329oMb73l8yQVJtFMEKuA0BJB9WDfPqqarqoZg+dfAZqHHFsVfF0KTAaaRjFWeOQRK03cd19UX8a54mbkSHjtNRsU16FDrKNxORHNBDEDSBSR2iJSGugOHNAbSUSqhjztAiwI9ieISJngcWWgNTA/irFCjRpw1122svmMGVF9KeeKizlzrPRwzjkwYECso3E5FbUEoaq7gVuACdgH/2hVTRWRQSKS0SvpNhFJFZE5wG1Az2D/KUBKsH8S8LiqRjdBgK1ofswxlih8mVLncmXTJmt3qFTJqpbi4mIdkcspKSrrNSclJWlKSkrub/Tii9CrF/zvf94Pz7nDpAqXXGLrQU+eDGeeGeuIXFZEZGbQ3nuQWDdSFzzXXWdLUd1zjy1q65zLsWHDbI2Gxx/35FCYeYLIrGRJeOopWLwYRoyIdTTOFTrTptlo6a5drbbWFV6eIMI591xo3x4eegg2box1NM4VGunpNs9SjRrWc8mn6y7cPEGEkzF4bsMGGDw41tE4Vyjs3WvDiX7/3SbhO+qoWEfkcssTRFaaNIGrr7bK1GXLYh2NcwXeY4/BuHE2fXfz5oc+3xV8niCy88gj1jfvX/+KdSTOFWiTJtk4h3/8A/75z1hH4/KKJ4jsVKtmrW3vvmstb865g/z2G/ToASedZL3Evd2h6PAEcSj33APHHuuD55wL7NwJM2fCCy/ANddAy5awZQu8/z6ULx/r6Fxe8jWpD6V8eXj4YVs493//g4suinVEzuUbVevx/cMP+7cff7RV4QCqVLEEceutNnzIFS0+kjoSe/ZYo/X27TB/PpQuHZ3XcS7Gfv/9wGQwY4Z15gM48khISoIWLfZvNWt6lVJhl91Iai9BRCIuzgbPnXsuPP883HFHrCNyLk/89Rf897/w+eeWEH791fbHxUHDhjZdRkYyOOUUG0fqig8vQURKFTp2hJQUK3NXqhS913IuynbutGm4H30UVqyAWrXg9NP3J4OmTa3E4Io+L0HkhYzBc02a2OC5p5+OdUTO5djOnTbCefBgKy20agWvvmrTcXtVkcvMezHlRKNG1m3j2WdhyZJYR+NcxHbtskRw0kk2TqFqVRg/Hr79Fv72N08OLjxPEDn18MO2oK4PnnOFwO7dMGoUnHwyXH+99Tr67DP4/nurMfXE4LLjCSKnjj8e+va1yWa++y7W0TgX1u7d8PrrlhiuvdbmRfr4Y5g+3fpaeGJwkfAEcTj69rUyug+ecwXMnj3w5ps2JqFnT4iPh48+sr4V55/vicHljCeIw1GunFU1TZtmJQnnYmzPHltO/dRTbUbVI46wcZ2zZkGXLp4Y3OEp9t1cVWHgQKufrVEjBxfu2WN9AbduhQULoEyZHL+2c3v3wujRsHSpPc/4IBeJ7DFYA/Trr9uvYYMG9vt84YVQwv/9cxHwbq7Z+Pln67E6bJgtIHfZZRFeGBdn3V47doTnnvOls1yOTZsGt9xi8xrlVv36NqfkxRd7YnB5J6q/SiLSSUQWichiEekX5nhPEVkrIrOD7fqQY1eLyC/BdnW0YjzpJJg92752725LQGzeHOHFHTpAp042LXh6erRCdEXMmjXWPtCqFaxebW0GO3bs37Zvh23bbPvzTyukbt1qE+Jt2WK/n5s22bZxo02F8dNPtpKbJweXp1Q1KhsQBywB6gClgTlA/Uzn9ASeC3NtJWBp8DUheJyQ3es1b95cc2PnTtX+/VVLlFCtXVv1228jvHDePNW4ONWTT1adNStXMbiibedO1aefVo2PVy1VSvXee1U3b451VK64A1I0i8/VaP6/0QJYrKpLVXUnkAx0jfDajsAXqrpeVTcAXwCdohQnYEMbBg2CKVOsXaJNG3jwQesumK0GDWzE0aZNNq3lkCFWsexciC++sHGWd91lv1upqfD449bLyLmCKpoJohqwIuT5ymBfZheJyFwReV9EMpqJI7pWRG4UkRQRSVm7dm2eBN26NcyZA1dcYQnjzDMjGDR9zjkwb571I+zb16qeVq3Kk3hc4bZsGXTrZr8Su3bZWIRPP4XExFhH5tyhxbrG8mOglqo2wkoJr+fkYlV9SVWTVDWpSpUqeRZUhQrWKyQ5GRYutOmXXnvtEEMejj4aPvgAXn7Zhqk2amT9DF2xtG2blUDr14cJE2zuo59+sv8hnCssopkgVgGhHUerB/v2UdV0VQ2WHuEVoHmk1+aHyy6DuXNtAfZrrrFGwPXrs7lAxPrL/vgj1Kljiwtdf721MLpiQdX+TzjlFCuBXnABLFoE990HZcvGOjrnciaaCWIGkCgitUWkNNAdGBt6gohUDXnaBVgQPJ4AdBCRBBFJADoE+/JdzZowcaLVF48ZYwWDr746xEX16tk0HPfdZ3MqN2tmK6+4Ii011Sa+u/hiqFgRJk+Gd96B6tVjHZlzhydqCUJVdwO3YB/sC4DRqpoqIoNEpEtw2m0ikioic4DbsF5NqOp64GEsycwABgX7YiIuDu691/qtly8P7dtbU0PGsothlSpl9QqTJlnfxTPOgMceswF2rkjZuBHuvBMaN7aRy889Z1/bto11ZM7lTrEfSZ1Tf/4Jd99tg+qaNLHpDU455RAXbdgAvXvbSKazzoI33rCiiSvUtmyxZPD001b1eOONNiSmcuVYR+Zc5LIbSR3rRupCp1w5eOEFGDsWVq602qPhww/RHTYhweoa/vtfa59o1MiShSuUNm+2wmGtWlaL2KKFTYY3YoQnB1e0eAkiF9asscbr8eOhdGkbjX3qqQdudetaFdU+S5daH9rvv4errrLFhypUyNe43eHZtMmmZPn3v61Q2LkzDBhgCcK5wiq7EoQniFxShQ8/tAXfU1OtK2Na2v7jZcrYnPwHJI6TdlP7nUeJe+QhOOEEeOstm3fBFUgbN8LQobZt2gR//7slhqSwf1LOFS6eIPJZxgSvqakHbr/+uv+cI46Ak2ts5dRVX3DqthkknpdI7bsvonbjCiQkxC52t9+GDZYU/vMfSwwXXGCJoWnTWEfmXN7xBFFAbNkC8+fvL2mkpkLqT3tZtfrApqCKFZXatYU6daB27QO3WrUsubjoWb/eqpGGDbP2hm7doH9/65TgXFHj030XEPHxNl1Ty5ahe0uwaRMsHf8zywa/zbJ5W1hGU5aV/Bvz5x/DZ58JO3YceJ+qVQ9OHImJNvzimGMKz+Iwv/1m7fZvv23TUFSrlvV2zDGZ2nKiID0dnnnGmoW2bLHxDP37W58C54ojL0EUJKq2ovxdd9nw2/bt2fvU0/x+XGOWLeOAbelS+7pixYFzA1aoYIki85aYWDDawnftsrmIXn0Vxo2zYSGtW1sCWLXKtjVrDh4uEhdniTGrBFKunCXGEiUO3g61f+dOeOUV67L6559wySWWGBo0iM175Fx+8iqmwmbXLnjxRZvMZ8MGW3X+kUfguOPCnvrrr7B4sS1+FLotX37g/FHHHXdw0qhXz3paRXtBvPnzbVD5G2/AH3/Yh33PnrbVq3fguXv22DkZCSOrLeJ1OyIgYlOrPPCAdSRwrrjwBFFYbdhgieHZZ60f7b/+BX36RNwIsWOHzUSbOXH8/LN9AGcoUcK66CYl2bxTzZtbfXv58rkLf/Nmm/Bw5EiYPh1KlrT1ka+91hbiK5nLCs6tW/cnix07rCSlal8zb+H2h+5r08Z6mzlX3HiCKOx++cXm+vjwQ1s4+7HHoEePXC0ftnGj3fbnn23G2tmzbbDXmjV2vEQJ+8Bs3nx/4mjSxKpysqNqa2qMHAnvvWero516Klx3nQ3/yMNJd51zecATRFHx9ddWgpg1y0ZnPfOMVeDnodWrbY3kjC1c0shc0ihXzkaVv/46jBplpZYKFSyHXXednV9YGs6dK248QRQle/daRf5999mn+SWXwBNPWFemKAlNGikp9jU0adSpY43me/dCu3ZWhdStGxx5ZNRCcs7lEU8QRdGff8JTT8GTT1qr7k03Qb9+cOyx+fLyq1fvTxZz51qPn2uusWThnCs8PEEUZatWWZ/M11+3FWluuQXuucdWuHPOuUPI9WyuIlJOREoEj+uJSBcRKZWXQbrDVK2atQgvWGBzQTz1lA23HjDAWqKdc+4wRdoNZgpQVkSqAZ8DVwKvRSsodxjq1bNJ/+bNg06d4OGHrV3ikUdsWLBzzuVQpAlCVHUb0A14XlUvAXw4UUF06qnWv/THH61zf//+liiefNLaLZxzLkIRJwgRaQVcDnwa7IvyzDguV5o0sVWNpk+3fqb33mtDpocO5aDJnbgmaisAABneSURBVJxzLoxIE8QdwL+AD4N1pesAk6IXlsszLVrYikbffGOlizvvhBNPtGXxdu6MdXTOuQIsogShql+rahdVfSJorF6nqrdFOTaXl1q3hokT4auvrBH7ppus3eLVV21CJ+ecyyTSXkxvi0gFESkH/ATMF5G+EVzXSUQWichiEemXzXkXiYiKSFLwvJaIbBeR2cE2ItJvyB1Cu3YwdaqVKo45Bq6/Hk45xbrJZruwtnOuuIm0iqm+qm4GLgDGAbWxnkxZEpE4YDhwLlAf6CEi9cOcFw/cDkzPdGiJqjYJtl4RxukiIWKz5U2fbu0U8fE2repJJ1mJwquenHNEniBKBeMeLgDGquou4FAj7FoAi1V1qaruBJKBrmHOexh4AvCW0/wmYgssz5pliaJSJStRJCbCiBHw11+xjtA5F0ORJogXgTSgHDBFRE4ADjUbfzVgRcjzlcG+fUSkGVBDVT/lYLVF5EcR+VpE2oR7ARG5UURSRCRl7dq1EX4r7iAZieKHH2zBouOPh969rdfTc895ryfniqlIG6mHqWo1VT1PzXKgXW5eOGjsfga4K8zh34CaqtoU6AO8LSIHrYemqi+papKqJlXxeaRzTwTOPRe++w6++MLGT9x6q02w9O9/w7ZtsY7QOZePIm2krigiz2T8ty4iT2OlieysAmqEPK8e7MsQDzQAJotIGnA6MFZEklT1L1VNB1DVmcASINO6Yy5qROCcc2xhh0mTbI7vPn0sYTz1lK3U45wr8iKtYhoJbAEuDbbNwKhDXDMDSBSR2iJSGugOjM04qKqbVLWyqtZS1VrANKCLqqaISJWgkZtgzEUisDQH35fLCyJw9tnWNXbqVBt8d8891k32scfyds1P51yBE2mCqKuqDwYNzktV9SEg24mdVXU3cAswAVgAjA4G2Q0SkS6HeL2zgLkiMht4H+ilqusjjNVFw5lnwoQJ8P330LKlrUdRqxYMGuSTAjpXREU03beIfA/0VdVvguetgSGq2irK8UWs2E73HSspKTYR4Ecf2fJxt98Od9xhPaGcc4VGrqf7BnoBw0UkLWgveA74Zx7F5wqjpCQYM8YmBTznHJs99oQTrGSxbl2so3PO5YFIezHNUdXGQCOgUdC76P+iGpkrHJo0gQ8+sGnGO3eGxx+3qqe+feH332MdnXMuFyItQQCgqpuDEdVg3U+dMw0aQHIypKbChRfCM89Yr6c777T1SZ1zhU6OEkQmkmdRuKLjlFPgjTdg4UK47DJ49lkbR3HLLbBixaGvd84VGLlJEEVjMWsXHYmJMGoU/PwzXHklvPiijczu1QvS0mIdnXMuAtkmCBHZIiKbw2xbgOPzKUZXmNWpAy+/DIsX2zxPo0ZZ8rj+eliyJNbROeeykW2CUNV4Va0QZotX1ZL5FaQrAk44AZ5/3pJC797w5ps2e2zPnlbKcM4VOLmpYnIu56pXh2HDYNkyuO02GD3a2i0uv9zaLZxzBYYnCBcbVataT6e0NLjrLhtTUb8+9OgB8+fHOjrnHJ4gXKwdcww8+aQlinvugY8/ti6zl10GP/0U6+icK9Y8QbiCoUoVG2SXlgb9+tm6FA0bwqWX2iA851y+8wThCpbKleHRRy1R3H+/rZ3dqBFcfDHMnRvr6JwrVjxBuILp6KNtMsC0NOjf3xYwatwYunWD2bNjHZ1zxYInCFewVapkU4qnpcGDD9raFE2bwgUX2Frazrmo8QThCoeEBBg40BLFwIHw9dfQvDl06QIzZ8Y4OOeKJk8QrnA56igrSaSlWcnim29s6vFOnax0EcH6Js65yHiCcIVTxYrWNpGWBoMH27oU7dtbsnj3Xdi9O9YROlfoeYJwhVuFCrZI0fLl8NJLsHUrdO9u8z09+yz8+WesI3Su0PIE4YqGsmXhhhtgwQL48EM4/nibyqNmTRgwAP74I9YROlfoRDVBiEgnEVkkIotFpF82510kIioiSSH7/hVct0hEOkYzTleElChhPZy+/dbaJ9q02b8cau/eNquscy4iUUsQIhIHDAfOBeoDPUSkfpjz4oHbgekh++oD3YFTgU7A88H9nItc69Y2x9OCBXDFFTByJNSrZ4Pupk8/9PXOFXPRLEG0ABar6lJV3QkkA13DnPcw8ASwI2RfVyBZVf9S1WXA4uB+zuXcySfbmhQZ03hMnAinnw5t28Inn8DevbGO0LkCKZoJohoQusbkymDfPiLSDKihqp/m9FrncqxqVZvG49dfbSbZZcvg73+3OZ9eew127ox1hM4VKDFrpBaREsAzwF25uMeNIpIiIilr167Nu+Bc0RYfD3feaYsXvfkmlCwJ11wDJ54I//mP93xyLhDNBLEKqBHyvHqwL0M80ACYLCJpwOnA2KCh+lDXAqCqL6lqkqomValSJY/Dd0VeqVK2UNHs2TBuHNSuDXfcYT2fHnoI0tNjHaFzMRXNBDEDSBSR2iJSGmt0HptxUFU3qWplVa2lqrWAaUAXVU0JzusuImVEpDaQCPwQxVhdcSZiI7G//tp6P515pk3nUbOmlTRWrDjkLZwriqKWIFR1N3ALMAFYAIxW1VQRGSQiXQ5xbSowGpgPjAduVtU90YrVuX3OOAM++sgWK7r4YhtsV6eOVUEtWBDr6JzLV6JFZO6apKQkTUlJiXUYrqhZvtwatF9+GXbssDEW/fpBC+9U54oGEZmpqknhjvlIaueyc8IJ1nC9fDk88ABMngwtW8L//R98/rlPDuiKNE8QzkWiShWbPXb5cnj6aVi0CDp2tCnHR4+GPV4D6ooeTxDO5UR8PPTpA0uXwquvWpfYyy6DU06x5z6WwhUhniCcOxxlysC118L8+fD++zar7PXXW4P20KE+lsIVCZ4gnMuNuDi46CKYMQMmTLDBdnfeaW0XDz8MGzbEOkLnDpsnCOfyggh06GCN2N9+C61a2TTjNWvCPffAb7/FOkLncswThHN57Ywz4OOPYc4cm+vp6adtlHbv3tZ24Vwh4QnCuWhp1Ajeftt6PF199f7pxq+4wgbiOVfAeYJwLtpOPBFefNFmj73jDlujomFDG3Tn61K4AswThHP55fjjYcgQG0sxcCBMmWLrUrRvD5995mMpXIHjCcK5/Hb00fDgg5YohgyxOZ46d4bERHjiCfCp610B4QnCuViJj4e77rKV7pKTrcdTv35QvbpNQ/7NNz6Vh4spTxDOxVrp0jYae/JkSE2Ff/7TlkJt0wYaN4bnn4fNm2MdpSuGPEE4V5DUrw/DhsHq1TaDbMmScPPNUK2adZOdOzfWEbpixBOEcwVRuXI2dcfMmTBtmo3Wfu01K1G0bm1Lpe7YEesoXRHnCcK5gkzEphd/7TVYtcoG3a1dC1deaW0V99xja2s7FwWeIJwrLCpVsplkFy6EL76Atm1tMaMTT4SuXeEHX5XX5S1PEM4VNiVKwDnnwAcfWFfZAQNg6lQraXTsaI+dywOeIJwrzKpVg4ceskTxxBMwezacdZaVLr74wrvJulzxBOFcURAfb+0Ry5bZEqlLltjssqefbhMHeqJwhyGqCUJEOonIIhFZLCL9whzvJSLzRGS2iHwjIvWD/bVEZHuwf7aIjIhmnM4VGUceCbfdZgnixRfhjz+gSxdo2tQWNtq7N9YRukIkaglCROKA4cC5QH2gR0YCCPG2qjZU1SbAk8AzIceWqGqTYOsVrTidK5LKlIEbb4Sff7YeUNu3wyWXQIMG1kV29+5YR+gKgWiWIFoAi1V1qaruBJKBrqEnqGro8NBygJeDnctLpUrZVOPz59t0HiVLWhfZk06CV17xNbRdtqKZIKoBK0Kerwz2HUBEbhaRJVgJ4raQQ7VF5EcR+VpE2oR7ARG5UURSRCRlrU9w5lzW4uJsOo/Zs2268UqV4IYboG5deO45K2E4l0nMG6lVdbiq1gXuBR4Idv8G1FTVpkAf4G0RqRDm2pdUNUlVk6pUqZJ/QTtXWJUosX/MxPjxtnb2rbfaVOS33+4LGbkDRDNBrAJqhDyvHuzLSjJwAYCq/qWq6cHjmcASoF6U4nSu+BHZP2bi66+hUycYMcIWMjrjDBg1Cv78M9ZRuhiLZoKYASSKSG0RKQ10B8aGniAiiSFPOwO/BPurBI3ciEgdIBHwxXydy2siNm7inXf2T+Wxfj1ce62VKm66yaqlXLEUtQShqruBW4AJwAJgtKqmisggEekSnHaLiKSKyGysKunqYP9ZwNxg//tAL1VdH61YnXNA5co2lceCBbbaXZcuto5206bQooXNLrtlS6yjdPlItIgMoElKStKUlJRYh+Fc0bJ+vXWLfeklW6uifHno0cO60DZvbiUQV6iJyExVTQp3LOaN1M65AqxSJRt4N28efPcdXHyxJYzTTrME8cILsGlTrKN0UeIJwjl3aCLQqpU1Xq9eDcOH26jsm26ytoqePWHiRNizJ9aRujzkCcI5lzNHHWWJ4ccfrbvsP/4BH35oM8zWqmXraqemxjpKlwc8QTjnDo+IVTW9/DKsWWMjtRs3hiFDbEqP5s1h6FD4/fdYR+oOkycI51zuHXGEjdT+5BPrLjt0qO2/806bkrxzZ0sgPmK7UPEE4ZzLW8cea6OyZ860qqa+fWHuXOv9dOyxcN11MHmyzyxbCHiCcM5FT/368NhjkJZmjdjdusHo0dCuHdSuDfffb0uougLJE4RzLvri4uD//s+mHl+zBt56C045BR5/3L62agX//S/s2BHrSF0ITxDOufxVrpz1fBo/HlauhKeesgF5V19t7RV33w2LF8c6SocnCOdcLFWtaglh4UL48kureho6FBITbcnUDz/0xY1iyBOEcy72RKB9e1sW9ddf4aGHbJGjbt1sbMVDD9kAPZevPEE45wqW44+HAQOsYXvMGBtTMXAg1KwJF11kJQ3vAZUvPEE45wqmkiVtcaPx461Nok8fW7vib3+Dk0+GZ56xtgsXNZ4gnHMFX9268OST1qj9xhtQpQrcdZc1avfsaRMJFpGZqQsSTxDOucKjbFm44gr49luYM8eSwwcfQOvW1rA9aBAs9bXF8oonCOdc4dSokU03vnq1ja844QRrq6hbF9q0sTmiNm6MdZSFmicI51zhFh9vYygmToTly23k9rp1tqjRccfBpZfaHFG7dsU60kLHE4RzruioUcOmG58/H2bMsCQxaRL8/e/WXpExR5S3V0TEE4RzrugRgaQkGDbMqqDGjoW2bWHECNvfoAE88YQ1ersseYJwzhVtpUpZCeK992weqBdfhIQEK2nUrGkLHb3+OmzZEutIC5yoJggR6SQii0RksYj0C3O8l4jME5HZIvKNiNQPOfav4LpFItIxmnE654qJhASrdvrmGxtb8eCDsGyZ9YY69libI2rcOJ/eIyAapbo4EYkDfgb+BqwEZgA9VHV+yDkVVHVz8LgLcJOqdgoSxTtAC+B44EugnqpmueBtUlKSpqSkROV7cc4VYarw/fc2vuLdd2HDBjjmGFu/4soroVkzq7IqokRkpqomhTsWzRJEC2Cxqi5V1Z1AMtA19ISM5BAoB2Rkq65Asqr+parLgMXB/ZxzLm+JwBlnWJfZ336zCQLbtLHnSUm2psWjj1oPqWImmgmiGrAi5PnKYN8BRORmEVkCPAnclsNrbxSRFBFJWbt2bZ4F7pwrpsqUgQsusEkD16yBl16yUdv332+TBrZtW6zGV8S8kVpVh6tqXeBe4IEcXvuSqiapalKVKlWiE6BzrnhKSIAbboApU2x09iOPwO+/7x9fcckl8NFHsHNnrCONmmgmiFVAjZDn1YN9WUkGLjjMa51zLnoylkddsMDGV/zznzZx4AUX2JoW111nS6kWsckDo5kgZgCJIlJbREoD3YGxoSeISGLI087AL8HjsUB3ESkjIrWBROCHKMbqnHOHljG+4j//gVWr4NNPoWNHmw/qssugcmVo2RL694epUwv96O2S0bqxqu4WkVuACUAcMFJVU0VkEJCiqmOBW0TkHGAXsAG4Org2VURGA/OB3cDN2fVgcs65fFeqFJx3nm27d1vJ4vPPbXvsMauSio+3tbg7dLCtbt1C1SMqat1c85t3c3XOFRgbN9oUHxMm2JaWZvtr17ZE0bGjJY6KFWMaJmTfzdUThHPORZMqLFliJYsJE+Crr2DrVoiLs+qojIRx2mm2L595gnDOuYJi1y6YNm1/wkhJsSSSkLA/WXTsaEuv5gNPEM45V1Clp9s62+PH27Zmje1v1Ag6dbKtdWsoXToqL+8JwjnnCgNVmDdvf7L45hsrcZQrZ20WGQmjTp08e0lPEM45Vxht3WqN3ePH2ySCy5bZ/sREq4bq1AnOPtsSyGHyBOGcc4Wdqs1AO2GCJYxJk2DbNqt6uvBCSE4+rNtmlyCiNg7COedcHhKxkkNiItxyC+zYYVVQEyZErX3CE4RzzhVGZcvaYkfnnBO1l4j5ZH3OOecKJk8QzjnnwvIE4ZxzLixPEM4558LyBOGccy4sTxDOOefC8gThnHMuLE8QzjnnwioyU22IyFpgeS5uURlYl0fhRIPHlzseX+54fLlTkOM7QVWrhDtQZBJEbolISlbzkRQEHl/ueHy54/HlTkGPLytexeSccy4sTxDOOefC8gSx30uxDuAQPL7c8fhyx+PLnYIeX1jeBuGccy4sL0E455wLyxOEc865sIpVghCRTiKySEQWi0i/MMfLiMi7wfHpIlIrH2OrISKTRGS+iKSKyO1hzjlbRDaJyOxgG5Bf8YXEkCYi84LXP2iNVzHDgvdwrog0y8fYTgp5b2aLyGYRuSPTOfn6HorISBH5Q0R+CtlXSUS+EJFfgq8JWVx7dXDOLyJydT7G95SILAx+fh+KyFFZXJvt70IU4xsoIqtCfobnZXFttn/vUYzv3ZDY0kRkdhbXRv39yzVVLRYbEAcsAeoApYE5QP1M59wEjAgedwfezcf4qgLNgsfxwM9h4jsb+CTG72MaUDmb4+cB4wABTgemx/DnvQYbBBSz9xA4C2gG/BSy70mgX/C4H/BEmOsqAUuDrwnB44R8iq8DUDJ4/ES4+CL5XYhifAOBuyP4+Wf79x6t+DIdfxoYEKv3L7dbcSpBtAAWq+pSVd0JJANdM53TFXg9ePw+0F5EJD+CU9XfVHVW8HgLsAColh+vnce6Av9VMw04SkSqxiCO9sASVc3N6PpcU9UpwPpMu0N/z14HLghzaUfgC1Vdr6obgC+ATvkRn6p+rqq7g6fTgOp5/bqRyuL9i0Qkf++5ll18wWfHpcA7ef26+aU4JYhqwIqQ5ys5+AN43znBH8gm4Oh8iS5EULXVFJge5nArEZkjIuNE5NR8Dcwo8LmIzBSRG8Mcj+R9zg/dyfoPM9bv4bGq+lvweA1wbJhzCsr7eC1WIgznUL8L0XRLUAU2MosquoLw/rUBflfVX7I4Hsv3LyLFKUEUCiJSHvgAuENVN2c6PAurMmkMPAuMye/4gDNVtRlwLnCziJwVgxiyJSKlgS7Ae2EOF4T3cB+1uoYC2ddcRO4HdgNvZXFKrH4XXgDqAk2A37BqnIKoB9mXHgr831JxShCrgBohz6sH+8KeIyIlgYpAer5EZ69ZCksOb6nq/zIfV9XNqro1ePwZUEpEKudXfMHrrgq+/gF8iBXlQ0XyPkfbucAsVf0984GC8B4Cv2dUuwVf/whzTkzfRxHpCZwPXB4ksYNE8LsQFar6u6ruUdW9wMtZvG6s37+SQDfg3azOidX7lxPFKUHMABJFpHbwH2Z3YGymc8YCGb1FLga+yuqPI68F9ZWvAgtU9Zkszjkuo01ERFpgP7/8TGDlRCQ+4zHWmPlTptPGAlcFvZlOBzaFVKfklyz/c4v1exgI/T27GvgozDkTgA4ikhBUoXQI9kWdiHQC7gG6qOq2LM6J5HchWvGFtmldmMXrRvL3Hk3nAAtVdWW4g7F8/3Ik1q3k+blhPWx+xno33B/sG4T9IQCUxaolFgM/AHXyMbYzsaqGucDsYDsP6AX0Cs65BUjFemRMA87I5/evTvDac4I4Mt7D0BgFGB68x/OApHyOsRz2gV8xZF/M3kMsUf0G7MLqwa/D2rUmAr8AXwKVgnOTgFdCrr02+F1cDFyTj/EtxurvM34PM3r2HQ98lt3vQj7F90bwuzUX+9Cvmjm+4PlBf+/5EV+w/7WM37mQc/P9/cvt5lNtOOecC6s4VTE555zLAU8QzjnnwvIE4ZxzLixPEM4558LyBOGccy4sTxDOHYKI7Mk0S2yezQwqIrVCZwJ1riApGesAnCsEtqtqk1gH4Vx+8xKEc4cpmM//yWBO/x9E5MRgfy0R+SqYTG6iiNQM9h8brK8wJ9jOCG4VJyIvi60D8rmIHBGcf5vY+iBzRSQ5Rt+mK8Y8QTh3aEdkqmK6LOTYJlVtCDwHDA32PQu8rqqNsInuhgX7hwFfq00U2AwbQQuQCAxX1VOBjcBFwf5+QNPgPr2i9c05lxUfSe3cIYjIVlUtH2Z/GvB/qro0mGhxjaoeLSLrsOkfdgX7f1PVyiKyFqiuqn+F3KMWtu5DYvD8XqCUqj4iIuOBrdiMs2M0mGTQufziJQjnckezeJwTf4U83sP+tsHO2LxWzYAZwQyhzuUbTxDO5c5lIV+/Dx5/h80eCnA5MDV4PBHoDSAicSJSMaubikgJoIaqTgLuxaaeP6gU41w0+X8kzh3aEZkWnh+vqhldXRNEZC5WCugR7LsVGCUifYG1wDXB/tuBl0TkOqyk0BubCTScOODNIIkIMExVN+bZd+RcBLwNwrnDFLRBJKnquljH4lw0eBWTc865sLwE4ZxzLiwvQTjnnAvLE4RzzrmwPEE455wLyxOEc865sDxBOOecC+v/AasyOVyTiZTfAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#-----------------------------------------------------------\n",
    "# Retrieve a list of list results on training and test data\n",
    "# sets for each training epoch\n",
    "#-----------------------------------------------------------\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = [*range(20)]\n",
    "\n",
    "#------------------------------------------------\n",
    "# Plot training and validation loss per epoch\n",
    "#------------------------------------------------\n",
    "plt.plot(epochs, loss, 'r')\n",
    "plt.plot(epochs, val_loss, 'b')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend([\"Loss\", \"Validation Loss\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "simplified-jacob",
   "metadata": {},
   "source": [
    "If you wish so, you can also check the training and validation accuracies of your model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "controlling-climb",
   "metadata": {
    "tags": [
     "graded"
    ]
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deZzN9f7A8dc7lH2XFKIbsjWWsVQqRSWJKCElEW26t+2We+tXrtLttmnTopRW2xSptInSosyQCGUJGST70tjGvH9/vL/DMc7MHMyZM8v7+Xicx5zz/X7POe9zZua8z/ezvD+iqjjnnHMZHRPrAJxzzuVNniCcc86F5QnCOedcWJ4gnHPOheUJwjnnXFieIJxzzoXlCcJFTEQ+FpFrc/rYWBKRFSLSPgqPqyJyanD9RRH5v0iOPYLn6S0inx1pnM5lRXweRMEmIjtCbpYEdgP7gts3qOrbuR9V3iEiK4DrVXVqDj+uAnVUdWlOHSsitYDlQDFVTc2JOJ3LStFYB+CiS1VLp1/P6sNQRIr6h47LK/zvMW/wJqZCSkTaikiyiNwjIn8Ar4lIBRH5UETWi8jm4Hr1kPt8KSLXB9f7isg3IvJ4cOxyEbn4CI+tLSIzRGS7iEwVkREi8lYmcUcS44Mi8m3weJ+JSOWQ/deIyEoR2Sgi92bx/rQSkT9EpEjItq4iMi+43lJEZorIFhFZKyLPicixmTzWaBF5KOT2P4P7rBGRfhmOvUREfhSRbSKySkSGhOyeEfzcIiI7ROSM9Pc25P5nikiiiGwNfp4Z6XtzmO9zRRF5LXgNm0VkUsi+LiIyN3gNy0SkQ7D9oOY8ERmS/nsWkVpBU1t/EfkdmBZsnxD8HrYGfyMNQ+5fQkSeCH6fW4O/sRIi8pGI3Jrh9cwTka7hXqvLnCeIwu0EoCJwMjAQ+3t4LbhdE9gJPJfF/VsBvwKVgUeBUSIiR3DsO8AsoBIwBLgmi+eMJMargOuA44FjgbsARKQB8ELw+CcGz1edMFT1B+Av4PwMj/tOcH0fcHvwes4A2gE3ZxE3QQwdgnguAOoAGfs//gL6AOWBS4CbROSyYN85wc/yqlpaVWdmeOyKwEfAM8FrexL4SEQqZXgNh7w3YWT3Pr+JNVk2DB5reBBDS+AN4J/BazgHWJHZ+xHGuUB94KLg9sfY+3Q8MAcIbRJ9HGgOnIn9Hd8NpAGvA1enHyQiccBJ2HvjDoeq+qWQXLB/1PbB9bbAHqB4Fsc3ATaH3P4Sa6IC6AssDdlXElDghMM5FvvwSQVKhux/C3grwtcULsb7Qm7fDHwSXL8fGBuyr1TwHrTP5LEfAl4NrpfBPrxPzuTY24CJIbcVODW4Php4KLj+KvBIyHF1Q48N87hPAcOD67WCY4uG7O8LfBNcvwaYleH+M4G+2b03h/M+A9WwD+IKYY57KT3erP7+gttD0n/PIa/tlCxiKB8cUw5LYDuBuDDHFQc2Y/06YInk+dz+fysIFz+DKNzWq+qu9BsiUlJEXgpO2bdhTRrlQ5tZMvgj/YqqpgRXSx/msScCm0K2AazKLOAIY/wj5HpKSEwnhj62qv4FbMzsubCzhW4ichzQDZijqiuDOOoGzS5/BHE8jJ1NZOegGICVGV5fKxGZHjTtbAVujPBx0x97ZYZtK7Fvz+kye28Oks37XAP7nW0Oc9cawLII4w1n/3sjIkVE5JGgmWobB85EKgeX4uGeK/ibHgdcLSLHAL2wMx53mDxBFG4Zh7DdCdQDWqlqWQ40aWTWbJQT1gIVRaRkyLYaWRx/NDGuDX3s4DkrZXawqi7EPmAv5uDmJbCmql+wb6llgX8fSQzYGVSod4DJQA1VLQe8GPK42Q05XIM1CYWqCayOIK6MsnqfV2G/s/Jh7rcK+Fsmj/kXdvaY7oQwx4S+xquALlgzXDnsLCM9hg3Ariye63WgN9b0l6IZmuNcZDxBuFBlsNP2LUF79gPRfsLgG3kSMEREjhWRM4BLoxRjAtBJRNoEHcpDyf5/4B3gH9gH5IQMcWwDdojIacBNEcYwHugrIg2CBJUx/jLYt/NdQXv+VSH71mNNO6dk8thTgLoicpWIFBWRHkAD4MMIY8sYR9j3WVXXYn0Dzwed2cVEJD2BjAKuE5F2InKMiJwUvD8Ac4GewfHxwBURxLAbO8sriZ2lpceQhjXXPSkiJwZnG2cEZ3sECSENeAI/ezhiniBcqKeAEti3s++BT3LpeXtjHb0bsXb/cdgHQzhHHKOqLgBuwT7012Lt1MnZ3G0M1nE6TVU3hGy/C/vw3g68HMQcSQwfB69hGrA0+BnqZmCoiGzH+kzGh9w3BRgGfCs2eqp1hsfeCHTCvv1vxDptO2WIO1LZvc/XAHuxs6g/sT4YVHUW1gk+HNgKfMWBs5r/w77xbwb+w8FnZOG8gZ3BrQYWBnGEuguYDyQCm4D/cfBn2htAY6xPyx0Bnyjn8hwRGQf8oqpRP4NxBZeI9AEGqmqbWMeSX/kZhIs5EWkhIn8LmiQ6YO3Ok7K7n3OZCZrvbgZGxjqW/MwThMsLTsCGYO7AxvDfpKo/xjQil2+JyEVYf806sm/GclnwJibnnHNh+RmEc865sApMsb7KlStrrVq1Yh2Gc87lK7Nnz96gqlXC7Ytqggg6HJ8GigCvqOojGfbXxCa0lA+OGayqU0SkGPAK0CyI8Q1V/W9Wz1WrVi2SkpKi8Cqcc67gEpGMs+/3i1oTUzAlfwQ2C7UB0CsolhbqPmC8qjYFegLPB9u7A8epamOsGNcNYrXwnXPO5ZJo9kG0xAq0/aaqe4Cx2PDFUAqUDa6Xw0oFpG8vJSJFsck6e7BZq84553JJNBPESRxclCyZg4uGgVVzvFpEkrEyAek13BOwui1rgd+Bx1V1U8YnEJGBIpIkIknr16/P4fCdc65wi3UndS9gtKo+EdTgeVNEGmFnH/uw6pQVgK9FZKqq/hZ6Z1UdSTARJj4+/pDxunv37iU5OZldu3Zl3OUKseLFi1O9enWKFSsW61Ccy9OimSBWc3DVyuocWlWyP9ABrLiWiBTHyvhehdWp3wv8KSLfAvHAbxyG5ORkypQpQ61atch8HRtXmKgqGzduJDk5mdq1a8c6HOfytGg2MSUCdcSWkzwW64SenOGY37FyvIhIfay++/pg+/nB9lJAa6wo2GHZtWsXlSpV8uTg9hMRKlWq5GeVzkUgaglCbcHxQcCnwCJstNICERkqIp2Dw+4EBojIT1jVzL5qU7tHAKVFZAGWaF5T1XlHEocnB5eR/004F5mo9kGo6hSs8zl02/0h1xcCZ4W53w5sqKtzzrnMbN0KkybB7t0wcGCOP7yX2sglkyZNQkT45ZfDbilzzrkD/voLxo2Drl3h+OOhb1947bWoPJUniFwyZswY2rRpw5gxY6L2HPv27YvaYzvnYmjXLjtT6NnTkkLPnvDDD3DTTTBzJnz3XVSe1hNELtixYwfffPMNo0aNYuzYsYB9mN911100atSI008/nWeffRaAxMREzjzzTOLi4mjZsiXbt29n9OjRDBo0aP/jderUiS+//BKA0qVLc+eddxIXF8fMmTMZOnQoLVq0oFGjRgwcOJD0ar1Lly6lffv2xMXF0axZM5YtW0afPn2YNOnAsgu9e/fm/fffz6V3xTmXpb174ZNP7AyhalU7Y5g6Ffr0gS+/hFWr4KmnoHVriFK/WqznQeSe226DuXNz9jGbNLFfUDbef/99OnToQN26dalUqRKzZ89m1qxZrFixgrlz51K0aFE2bdrEnj176NGjB+PGjaNFixZs27aNEiVKZPnYf/31F61ateKJJ54AoEGDBtx/v3XzXHPNNXz44Ydceuml9O7dm8GDB9O1a1d27dpFWloa/fv3Z/jw4Vx22WVs3bqV7777jtdff/3o3xfn3JHZtw++/hrGjoWEBNi4EcqWhW7d7Kzh/PMhF+fvFJ4EEUNjxozhH//4BwA9e/ZkzJgxLF++nBtvvJGiRe1XULFiRebPn0+1atVo0aIFAGXLls30MdMVKVKEyy+/fP/t6dOn8+ijj5KSksKmTZto2LAhbdu2ZfXq1XTt2hWwiWIA5557LjfffDPr16/n3Xff5fLLL98fj3Mul6jC999bv8L48bB2LZQsCV26QI8e0KEDHHdcTEIrPJ8GEXzTj4ZNmzYxbdo05s+fj4iwb98+RGR/EohE0aJFSUtL2387dAx/8eLFKVKkyP7tN998M0lJSdSoUYMhQ4ZkO96/T58+vPXWW4wdO5bXotTR5ZwLY/16GD0aXnoJli2zJNCxo50pXHIJlCoV6wi9DyLaEhISuOaaa1i5ciUrVqxg1apV1K5dm7i4OF566SVSU1MBSyT16tVj7dq1JCYmArB9+3ZSU1OpVasWc+fOJS0tjVWrVjFr1qywz5WeDCpXrsyOHTtISEgAoEyZMlSvXn1/f8Pu3btJSUkBoG/fvjwVJM8GDTIW23XO5ShVmDEDrroKqleHu++GE0+0RLFuHbz3Hlx5ZZ5IDlCYziBiZMyYMdxzzz0Hbbv88stZtGgRNWvW5PTTT6dYsWIMGDCAQYMGMW7cOG699VZ27txJiRIlmDp1KmeddRa1a9emQYMG1K9fn2bNmoV9rvLlyzNgwAAaNWrECSeccNBZyptvvskNN9zA/fffT7FixZgwYQKnnHIKVatWpX79+lx22WVRfR+cK9Q2b4Y33rCzhUWLoFw5uPFGuOEGyMNfzArMmtTx8fGaccGgRYsWUb9+/RhFlD+kpKTQuHFj5syZQ7ly5WIdTq7xvw0Xdao2FPXFF61/YdcuaNXKEsOVV1o/Qx4gIrNVNT7cPj+DKMSmTp1K//79uf322wtVcnAuqrZtg7fftrOFn36C0qVtqOoNN9jIx3zEE0Qh1r59e1auzHS1Qefc4Zgzx84W3nnHZjs3aWK3r7oKypSJdXRHxBOEc84dqT17YMwYGDECEhOhRAkbhXTjjdCiRdQmsOUWTxDOOXe4tmyxJqRnnoE1a6yj+Zln4JproHz5WEeXYzxBOOdcpNLLW7z8MmzfDu3awauvwoUX5vuzhXA8QTjnXHZ++gkef9xKYKjaKKS77oJMhpwXFD5RLorOO+88Pv3004O2PfXUU9x0002Z3qdt27akD9ft2LEjW7ZsOeSYIUOG8Pjjj2f53JMmTWLhwoX7b99///1MnTr1cMLP0m233cZJJ5100Axv5woUVSuOd9FF1uE8cSIMGmSznt95p8AnB4hyghCRDiLyq4gsFZHBYfbXFJHpIvKjiMwTkY4h+04XkZkiskBE5gfrVecrvXr12l+9Nd3YsWPp1atXRPefMmUK5Y+wPTNjghg6dCjt27c/osfKKC0tjYkTJ1KjRg2++uqrHHnMcNJnmTuXq/buPZAALrgA5s2Dhx+25qXhw+Hkk2MdYa6JWoIQkSLY0qEXAw2AXiKSccrgfdhSpE2xNaufD+5bFHgLuFFVGwJtgb3RijVarrjiCj766CP27NkDwIoVK1izZg1nn302N910E/Hx8TRs2JAHHngg7P1r1arFhg0bABg2bBh169alTZs2/Prrr/uPefnll2nRogVxcXFcfvnlpKSk8N133zF58mT++c9/0qRJE5YtW0bfvn33l9744osvaNq0KY0bN6Zfv37s3r17//M98MADNGvWjMaNG2e6uNGXX35Jw4YNuemmmw5a32LdunV07dqVuLg44uLi+C6oUf/GG29w+umnExcXxzXXXANwUDxgZcvTH/vss8+mc+fO+0t/XHbZZTRv3pyGDRsycuTI/ff55JNPaNasGXFxcbRr1460tDTq1KnD+vXrAUtkp5566v7bzmVp+3ZLAKeeCr172ypto0bBihXwr39BhQqxjjDXRbMPoiWwVFV/AxCRsUAXYGHIMQqklywtB6wJrl8IzFPVnwBUdePRBhOLat8VK1akZcuWfPzxx3Tp0oWxY8dy5ZVXIiIMGzaMihUrsm/fPtq1a8e8efM4/fTTwz7O7NmzGTt2LHPnziU1NZVmzZrRvHlzALp168aAAQMAuO+++xg1ahS33nornTt3plOnTlxxxRUHPdauXbvo27cvX3zxBXXr1qVPnz688MIL3HbbbYDVcZozZw7PP/88jz/+OK+88soh8YwZM4ZevXrRpUsX/v3vf7N3716KFSvG3//+d84991wmTpzIvn372LFjBwsWLOChhx7iu+++o3LlymzatCnb93XOnDn8/PPP1K5dG4BXX32VihUrsnPnTlq0aMHll19OWloaAwYMYMaMGdSuXZtNmzZxzDHHcPXVV/P2229z2223MXXqVOLi4qhSpUq2z+kKseRkG6b64os2Oumcc+x2x45wTOFuhY/mqz8JWBVyOznYFmoIcLWIJGNrV98abK8LqIh8KiJzROTuKMYZVaHNTKHNS+PHj6dZs2Y0bdqUBQsWHNQclNHXX39N165dKVmyJGXLlqVz58779/3888+cffbZNG7cmLfffpsFCxZkGc+vv/5K7dq1qVu3LgDXXnstM2bM2L+/W7duADRv3pwVK1Yccv89e/YwZcoULrvsMsqWLUurVq3297NMmzZtf/9KkSJFKFeuHNOmTaN79+5UrlwZsKSZnZYtW+5PDgDPPPMMcXFxtG7dmlWrVrFkyRK+//57zjnnnP3HpT9uv379eOONNwBLLNddd122z+cKGVVrNnroIZurUKMGPPootG9vpTG++go6dSr0yQFiP4qpFzBaVZ8QkTOAN0WkURBXG6AFkAJ8EdQL+SL0ziIyEBgIULNmzSyfKEbVvunSpQu33347c+bMISUlhebNm7N8+XIef/xxEhMTqVChAn379s22LHdm+vbty6RJk4iLi2P06NH7V5o7UscFdeeLFCkStg/g008/ZcuWLTRu3BiwWk4lSpSgU6dOh/U8oSXM09LS9jfDAZQKqWT55ZdfMnXqVGbOnEnJkiVp27Ztlu9VjRo1qFq1KtOmTWPWrFm8/fbbhxWXK6D27rWFeN5/HyZPtmYjEauN9N//2qikU06JdZR5TjRT5GqgRsjt6sG2UP2B8QCqOhMoDlTGzjZmqOoGVU3Bzi4OGTKgqiNVNV5V4/NqM0Lp0qU577zz6Nev3/6zh23btlGqVCnKlSvHunXr+Pjjj7N8jHPOOYdJkyaxc+dOtm/fzgcffLB/3/bt26lWrRp79+496MOwTJkybN++/ZDHqlevHitWrGDp0qWAVXk999xzI349Y8aM4ZVXXmHFihWsWLGC5cuX8/nnn5OSkkK7du144YUXAFtSdevWrZx//vlMmDCBjRutlTC9ialWrVrMnj0bgMmTJ7N3b/gupq1bt1KhQgVKlizJL7/8wvfffw9A69atmTFjBsuXLz/ocQGuv/56rr76arp3775/rQxXCG3bZgvw9O5t6zi3awcjR0KjRjaPYc0aW8958GBPDpmIZoJIBOqISG0RORbrhJ6c4ZjfgXYAIlIfSxDrgU+BxiJSMuiwPpeD+y7ylV69evHTTz/tTxBxcXE0bdqU0047jauuuoqzzjory/s3a9aMHj16EBcXx8UXX3xQGe8HH3yQVq1acdZZZ3Haaaft396zZ08ee+wxmjZtyrJly/ZvL168OK+99hrdu3encePGHHPMMdx4440RvY6UlBQ++eQTLrnkkv3bSpUqRZs2bfjggw94+umnmT59Oo0bN6Z58+YsXLiQhg0bcu+993LuuecSFxfHHXfcAcCAAQP46quv9q+lXSqT+vcdOnQgNTWV+vXrM3jwYFq3bg1AlSpVGDlyJN26dSMuLo4ePXrsv0/nzp3ZsWOHNy8VRqtWWf/BRRdB5cq2Ittnn8Fll9kw1Q0b4IMP4Prr4YQTYh1tnhfVct/BsNWngCLAq6o6TESGAkmqOjkY1fQyUBrrsL5bVT8L7ns18K9g+xRVzbIfwst9u3RJSUncfvvtfP3115ke438bBciCBbZ+8/vvw48/2rY6dWzJzi5d4IwzwM8kMxWzct+qOgVrHgrddn/I9YVA2K/PqvoWNtTVuYg98sgjvPDCC973UNBt22azmkeNglmzrD/hjDPgkUcsKYScTbsjF+tOaudy1ODBgxk8+JA5ma4gUIVvvrGkMGECpKRAw4bw5JNWUrtq1VhHWOAU+AShqkgBLKLljlxBWUWx0PjjD3j9dSuKt3ixra3Quzf07w8tWxbIInl5RYFOEMWLF2fjxo1UqlTJk4QDLDls3LiR4sXzXeWWwiU1FaZMsbOFjz6CffugTRub0dy9O2QyqMHlrAKdIKpXr05ycrKXWnAHKV68ONWrV491GC6cJUssKbz+up05VK0Kd94J/fpBvXqxjq7QKdAJolixYgfNyHXO5UEpKTYKadQomDHDRhx17GhNSB07QrFisY6w0CrQCcI5l4f9/LOtyvbmm7B1qxXJ++9/oU8fOPHEWEfn8AThnMtNO3faCKSXXoLvvoPjjoMrroABA6xInvcV5imeIJxz0bdokSWFN96AzZuhbl144gm49lqoVCnW0blMeIJwzkXH7t3w7ruWGGbMsL6Ebt3ghhugbVs/W8gHPEE453LW4sVWFG/0aNi40Qrh/e9/0LevFc1z+YYnCOfc0duzByZNskV3pk+HokWt5MUNN1gVVV9bIV/yBOGcO3Lbtllfwosvwp9/Qq1aMGyYzVvwaqn5nicI59zh27vX+hb+8x8rod25M9x0E1xwgVdOLUA8QTjnIqcK771nJS+WLLHO5sceg/iw1aJdPucNg865yHz7LZx1ls1bKFYMPvwQpk3z5FCAeYJwzmXt119teGqbNraW8yuvwE8/wSWX+FDVAs4ThHMuvHXr4JZbbM2Fzz+HBx+0ZqX+/W2UkivwopogRKSDiPwqIktF5JBVXESkpohMF5EfRWResERpxv07ROSuaMbpnAvx11+WDE491Tqib7gBli2D++7zMtuFTNQShIgUAUYAFwMNgF7BGtSh7gPGq2pToCfwfIb9TwIfRytG51yI1FRrPqpTB+6/Hy680NZ7HjHCJ7gVUtE8g2gJLFXV31R1DzAW6JLhGAXKBtfLAWvSd4jIZcByYEEUY3TOqdqiPE2aWNG8WrVsac933/U1GAq5aCaIk4BVIbeTg22hhgBXi0gyMAW4FUBESgP3AP/J6glEZKCIJIlIki8K5Nxh2rsXxo+Hs8+GTp1sNvS77x4YreQKvVh3UvcCRqtqdaAj8KaIHIMljuGquiOrO6vqSFWNV9X4KlWqRD9a5wqCNWtgyBA4+WTo0QNWr4bnnrPmpG7dfGSS2y+aQxFWAzVCblcPtoXqD3QAUNWZIlIcqAy0Aq4QkUeB8kCaiOxS1eeiGK9zBZcqfP219Se89571N3ToYEX1Lr7YZz+7sKKZIBKBOiJSG0sMPYGrMhzzO9AOGC0i9YHiwHpVPTv9ABEZAuzw5ODcEdixA956C55/HubPh/Ll4e9/t7IYp54a6+hcHhe1BKGqqSIyCPgUKAK8qqoLRGQokKSqk4E7gZdF5Hasw7qvqmq0YnKu0Pj1V0sKo0dbQb0mTWyEUq9eULJkrKNz+YQUlM/j+Ph4TUpKinUYzsVOaqqVvxgxAqZOtXIY3bvbZLczzvC+BReWiMxW1bD1Unw6pHP53fr1dnbw4ovw++9QvTo89BBcfz1UrRrr6Fw+5gnCufxq7VqrpPrii7BzJ5x/PgwfbqW3vRSGywH+V+RcfpOcDI8+aiOQUlPh6qvh7ruhQcZCBc4dHU8QzuUXv/8OjzwCo0ZBWhpce62ty/C3v8U6MldAeYJwLq9bsQIefthGJAFcd50lhlq1YhiUKww8QTiXVy1bZonhjTfgmGOsTtI990DNmrGOzBUSniCcy2sWL4Zhw+Dtt22o6s03Wx/DSRlLmTkXXZ4gnMsrFi2yxDBmDBx3nM14/uc/oVq1WEfmCilPEM7F2vz5lhjGj4cSJeDOO+3icxhcjHmCcC4WUlNh8mSrojp9OpQubf0Ld9wBXpnY5RGeIJzLTemznl94AVatsg7nRx6xWc+VKsU6OucO4gnCudyQlGRnC2PHwu7dNuv5mWdsoR6f9ezyKP/LdC5a9uyBCRMsMXz/PZQqBf37W/E8n/Xs8gFPEM7ltDVrrD7SyJGwbh3UqQNPP20zn8uVi3V0zkXME4RzOUHV1nJ+9llbsW3fPrjkEhg0CC64wCa6OZfPeIJw7mjs2GH9CiNGwNy5tmLbP/5hK7Z5jSSXz3mCcO5IzJljTUjvvAPbt0PjxvDSS9C7t/U1OFcARPW8V0Q6iMivIrJURAaH2V9TRKaLyI8iMk9EOgbbLxCR2SIyP/h5fjTjdC4i27ZZEoiPh+bN4fXXoVs3a1r66ScYONCTgytQonYGISJFgBHABUAykCgik1V1Ychh9wHjVfUFEWkATAFqARuAS1V1jYg0wta19kI0Lvep2hDVkSOtBMZff9nZwnPP2dlC+fKxjtC5qIlmE1NLYKmq/gYgImOBLkBoglCgbHC9HLAGQFV/DDlmAVBCRI5T1d1RjNe5A7ZutWJ5I0fa2UHJktCzp50ltGzp6zu7QiGaCeIkYFXI7WSgVYZjhgCficitQCmgfZjHuRyYEy45iMhAYCBATS+B7I6Wqs1XePll63jeuROaNIHnn4errvIhqq7QiXUndS9gtKo+ISJnAG+KSCNVTQMQkYbA/4ALw91ZVUcCIwHi4+M1l2J2Bc3mzfDWW3a28PPP1o9w9dV2ttC8uZ8tuEIrmgliNVAj5Hb1YFuo/kAHAFWdKSLFgcrAnyJSHZgI9FHVZVGM0xVWO3faBLaHH7aRSPHxliR69oQyZWIdnXMxF81RTIlAHRGpLSLHAj2ByRmO+R1oByAi9YHiwHoRKQ98BAxW1W+jGKMrjNLSbHjqaafZ0p1t21pHdGKirdrmycE5IIoJQlVTgUHYCKRF2GilBSIyVEQ6B4fdCQwQkZ+AMUBfVdXgfqcC94vI3OByfLRidYXIN99A69Y2AqlSJZg2zcpuN28e68icy3PEPo/zv/j4eE1KSop1GC6vWrrU1lt47z1bunPYMLjmGi+B4Qo9EZmtqvHh9vl/hyvYNm2C22+36qmffgpDh9qaz9de68nBuWzEehSTc9GxZwBrJ5MAACAASURBVI/VR3rwQZvT0K+fJQdf39m5iGX7FUpELhUR/6rl8gdVePddO2O44w5o0cKK6L38sicH5w5TJB/8PYAlIvKoiJwW7YCcO2KzZsE558AVV0Dx4vDxx9as1LhxrCNzLl/KNkGo6tVAU2AZMFpEZorIQBHxsYAub1i50mY6t2pl/QsvvWRnDR06xDoy5/K1iJqOVHUbkACMBaoBXYE5QYkM52IjMdGGq556KkycCPfea6OVBg70dZ6dywHZ/hcFcxauw+YlvAG0VNU/RaQkVnjv2eiG6FyI1FSYNAmGD4fvvrNJbbfeaiOVatTI/v7OuYhF8jXrcmC4qs4I3aiqKSLSPzphOZfBli0wapQt6blyJZxyCjz1FFx3HZQtm/39nXOHLZIEMQRYm35DREoAVVV1hap+Ea3AnANgyRJ45hl47TVbi+Hcc61+UqdOUKRIrKNzrkCLJEFMAM4Mub0v2NYiKhE5pwrTp9sZwocfWn/CVVfZWs9Nm8Y6OucKjUgSRFFV3ZN+Q1X3BMX3nMtZu3bZqm1PPQXz5kGVKvB//wc33QQnnBDr6JwrdCJJEOtFpLOqTgYQkS7YkqDO5Yx16+CFF+zy5582b2HUKDtrKF481tE5V2hFkiBuBN4WkecAwVaJ6xPVqFzhsHUrPPKInTHs2mX9CrffDued54v0OJcHZJsggsV6WotI6eD2jqhH5Qq23bttGc+HHrJier17w/33Q926sY7MORciotlEInIJ0BAoLsE3O1UdGsW4XEGUlmZ9DPfdBytWwAUXwP/+5x3PzuVRkRTrexGrx3Qr1sTUHTg5ynG5gmbqVFvS8+qroXx5q5H02WeeHJzLwyIptXGmqvYBNqvqf4AzAG8LcJGZOxcuusjOFjZtgjffhNmz4cILYx2Zcy4bkSSIXcHPFBE5EdiL1WPKloh0EJFfRWSpiAwOs7+miEwXkR9FZJ6IdAzZ96/gfr+KyEWRPJ/LQ1assBXbmja19Z6feAJ++cXOIHyhHufyhUj6ID4QkfLAY8AcQIGXs7uTiBQBRgAXAMlAoohMVtWFIYfdh61V/YKINACmALWC6z2xfo8TgakiUldV9x3Ga3OxsHEjPPwwPPecJYJ77oHBg61ZyTmXr2SZIIKFgr5Q1S3AuyLyIVBcVbdG8NgtgaWq+lvwWGOBLliBv3QKpBfSKQesCa53Acaq6m5guYgsDR5vZmQvy+W6nTutJMZ//wvbtkHfvvCf/3gBPefysSzP9VU1DTsLSL+9O8LkAHASNmciXXKwLdQQ4GoRScbOHtLLh0dyX4J1KZJEJGn9+vURhuVylCq8/roNUR08GNq0sVnQr77qycG5fC6SxuAvRORykajMXOoFjFbV6kBH4M3DWd5UVUeqaryqxlepUiUK4bks/fYbtG9vZwvVqln9pA8/hEaNYh2Zcy4HRPJhfANWnG+3iGwTke0isi2C+60GQr9CVg+2heoPjAdQ1ZlAcaByhPd1sbJvn63H0KiRLdrz4ovw/ffQtm2sI3PO5aBIlhwto6rHqOqxqlo2uB1JAf5EoI6I1A6K+/UEJmc45negHYCI1McSxPrguJ4icpyI1AbqALMif1kuahYsgLPOgjvugPPPh4UL4YYbfGSScwVQJCvKnRNue8YFhMLsTxWRQcCnQBHgVVVdICJDgaSg+N+dwMsicjvWYd1XVRVYICLjsQ7tVOAWH8EUY3v2WN2khx6yBXrefht69fKaSc4VYGKfx1kcIPJByM3i2Gii2ap6fjQDO1zx8fGalJQU6zAKpsRE6N8f5s+Hnj1ttJL3+ThXIIjIbFWND7cvkmJ9l2Z4sBrAUzkUm8vLUlLggQfgySdtPYb334fOnWMdlXMul0RUrC+DZKB+Tgfi8pivvoLrr4elS2HAAHjsMShXLtZROedyUSR9EM9i/QNgndpNsBnVriDats1mP7/4IpxyCnzxhXVGO+cKnUjOIEIb9lOBMar6bZTicbH00Udw442wZo2NUnrwQShZMtZROediJJIEkQDsSh9FJCJFRKSkqqZENzSXazZsgNtus5FJDRtCQgK0ahXrqJxzMRbRTGqgRMjtEsDU6ITjclVKivUt1KsH48fDkCEwZ44nB+ccENkZRPHQZUZVdYeIeLtDfrZ7N7zyCgwbBmvX2noNjz/uJTKccweJ5AziLxFpln5DRJoDO6MXkoua1FQrolevHgwaBKeeaqOVPvnEk4Nz7hCRnEHcBkwQkTXYkqMnYEuQuvwiLc2akB54ABYvtqU/X3rJVnXzmdDOuUxEMlEuUUROA+oFm35V1b3RDcvlCFX44AP4v/+zEtyNGsHEidCliycG51y2sm1iEpFbgFKq+rOq/gyUFpGbox+aO2KqMHUqnHGGJYOUFBuhNHcuXHaZJwfnXEQi6YMYEKwoB4CqbgYGRC8kd1S++84mtl1wgc1nePllq7h61VVQpEiso3PO5SORJIgioYsFBWtNHxu9kNwR+fFHuOQSK8W9cCE8/bT1N1x/PRQrFuvonHP5UCSd1J8A40TkpeD2DcDH0QvJHZbNm+Hmm2HsWKhQwdaEvvVWKFUq1pE55/K5SBLEPcBA4Mbg9jxsJJOLtfnzoWtX+P1364i+804vqOecyzGRjGJKE5EfgL8BV2JLgr4b7cBcNsaPh+uus4Tw1VfWIe2cczko0wQhInWBXsFlAzAOQFXPy53QXFipqfDvf1uJjDPPtLpJ1arFOirnXAGU1RnEL8DXQCdVXQoQLA0aMRHpADyNLTn6iqo+kmH/cCA94ZQEjlfV8sG+R4FLsI70z4F/aHbL3xV0GzbYim5ffGH9DsOHw7H5b7yAqr2UpUvtsnw5/O1v0KEDVKoU6+icc+myShDdgJ7AdBH5BBiLzaSOSDDaaQRwAbbIUKKITFbVhenHqOrtIcffCjQNrp8JnAWcHuz+BjgX+DLS5y9wfvzR+hv++MPKZVx3XawjypKqhZqeBDJetm079D7HHGMtZZ062aVhQ5+y4VwsZZogVHUSMElESgFdsJIbx4vIC8BEVf0sm8duCSxV1d8ARGRs8DgLMzm+F/BA+tNj618fiyWlYsC6iF5RQfTmmzBwIFSuDF9/DS1axDqi/bZutfl3ixcfmgRSQgrCFy0KtWpZ+aczz7Sf6ZeTT7aJ3h99BB9+CP/6l11OPvlAsmjbFooXj9WrdK5wksNptRGRCkB3oIeqtsvm2CuADqp6fXD7GqCVqg4Kc+zJwPdA9ZB1Jx4HrscSxHOqem+Y+w3ERlhRs2bN5itXroz4teQLe/fCXXfBM8/Auedax/Txx8csnI0brRp46GXp0gP7jz3WmopCP/xPPdW21awZ+XSM1athyhRLFlOnWqIpWRLat7dkccklcOKJ0XmNzhU2IjJbVePD7otWs/5hJoh7sORwa3D7VKzvIr0o4OfA3ar6dWbPFx8fr0lJSZntzn/WrYMrr4QZM2wxn0cfzdUJb3/8cXAimD3bRtOmq10bmjWzS9Om1hx00kk5P1l71y748ktLFh98cCCGZs0OnF00b27NU865w5dVgohkHsSRWg3UCLldPdgWTk/glpDbXYHv09ehEJGPgTOwTvOCb9Ys6NYNNm2Ct96C3r2j9lSqsGqVdXGkJ4I5c2yZiHR161qz0KBBBxJCxYpRC+kgxYtb53WHDvDss7BggSWLDz+Ehx6CoUOhalVrgbv7bihdOnficq4wiOYZRFFgMdAOSwyJwFWquiDDcadhs7Vrp49SEpEeWL2nDlgT0yfAU6r6QWbPV2DOIEaNshFKJ55olVebNMmxh96yxebWhV5+/tn6EcC+hdevf+DMoFkze/qyZXMshBy1caMtZTFhArz/viWKBx+Efv1yr+zUzp3W8lemDFx8MZQokf19nMtLYtLEFDxxR+ApbJjrq6o6TESGAkmqOjk4Zgi2at3gkPsVAZ4HzsE6rD9R1Tuyeq58nyB274Z//MPWaWjf3kpnHOGYz9274ZdfDk0GyckHjilXDho3PnBp0gTi4qytPz/64Qe44w6rVdiokS2Qd9FF0Xu+bdvg+edtpPGff9q20qXh0kutZbBDB+9Ud/lDzBJEbsrXCWLNGrjiCpg5E+65x5YCjfAr8Nq11iw0b96BRPDrrzafDqzbon79g5NB48ZQvXrBG0KqCu++a2/hb79ZgnjsMXu9OWXDBquD+OyzduZ10UUweDDs22dnEu++a2c2ZcpYpfUrr7R1mY47LudiyGtUC97fUmHiCSIv+/13G/y/davNb7jyykwP/eMPSwZJSQd+hvYV1Kp1aCKoW7fwFXPdvdu+3T/4oL2t/fpZX8XRTDhPToYnnoCRI21UVbduNhQ3PsO/1d69MH26JYv33rNaimXL2jIcV15pVdiPdm5jaiosWwaLFtnll1+sqatUKTsDLFny8K/v3WtNkFu3HvgZej2rn9u22SC70aPti4fLXzxB5FV//QVt2tjX3RkzrI0nsG7doclgzRrbJwKnnWYfTs2b2+X00/NuX0GsbNpkSWLECPtQvvtuq2d4OIVuly6F//0PXn/dVm7t3dvOUBo0yP6+e/fapPfx4607acsWKF/e5jteeSW0a5d18t65084GFy48kAwWLYIlS+yx0510kjVvpaQcuOzM4VXjy5Sx2MuVO/Az/XqxYvDKK/Yejxplr8/lH54g8qK0NPuUmDiRDW9/SmK59vuTwezZB/oLRKBevQPJID7e+gt8tE7kli61ZqB337W+/2HD4Jprsm7Fmz/fKqePG2cfgP36WYKpVevIYtizBz7/3JLFpEn2rbtiRfsw7d7dPoBDk8CiRbBihTXfgA0g+NvfrLkw/dKggX1RKFPm0OdLS7MkkZJi30NCk0fo7b/+ssuxxx784R+aBMqWzb7Fc/FiW5Nq9my48UY728qv/VmFTVYJAlUtEJfmzZtrfrLm9kf1WW7Rc05ZpSKqoCqiWq+eau/eqk8+qfrVV6rbtsU60oLjm29UW7Wy97pJE9WpUw89ZuZM1UsvtWNKl1b95z9V16zJ2Th27VKdPFn16qtVy5Sx50q/HHec6umnq/booTpkiOq4carz59t98rrdu1XvusteR4MGqvPmxToiFwls0FDYz1U/g8hFa9bYt9gJz6/nm18qoRxDgwZK9+7CeefZ/AJvJoouVTsrGDwYVq60WdmPPWa/m2HDrP+gYkUbUDZoUPTne+zaZc1QaWl2RlCrVv5fGfazz6BPH2tSe/xxuOUW78TOy7yJKYZWrw6SwgT49lv7gGooC+he/Xu6T76GBk3yXzXWgmDXLqtgMmzYgcKB1apZZZOBA70J72j9+afVk5wyxYb+vvqqlRJzeY8niFyWnGzLNEyYYOPywUYUde+wnStev5T6xZdDYmJM6yo5s2EDPPec9U306eNzF3KSqiXhu++25PDmm3D++bGOymXkCSIXrFp1ICnMnGnbTj/dOiC7d4d6J++ysYA//2xZI2TEknMF2dy5tozJ4sU2Amzo0NgNvU5NtaHhq1bZF7n0y2mn2RlPYRsSDrGrxVQo/PWXjUT5/HO7HRdnNYK6d7c5CIB9leozwGosvfeeJwdXqDRpYqObbrsNHnkEpk2Dd96xUVk5ae9e60sK/eAPTQSrVtlcorS0g+933HE2d2b4cOsz6djR+0zSeYI4Sg88YMlhyBAb5lenTpiDHn3Uiu499JAPEneFUqlS8PLLNvN8wAAbkPHCC4dfh3LXLhu2vHixzRFJ/7lihX34Z2wQKVUKatSwCXwXXWQ/q1c/sK16dRvS+8EH1v/UqZNVunnyyZydgZ9feRPTUZgzx9buuf56K6EU1gcfWM2FHj3sa5N/NXGF3O+/W2L45hubjzJixMFzOdLS7Bt/xiSwePHBc0PABhbUq2fl52vUOPiDv0YNGxUY6b/cnj3w4ov2ZW/rVujf35rDTjghJ1993uN9EFGQmgqtW9sopUWL7FvIIX7+2cponHaazZT2Up/OAfb/89BDNtO9dm37/rRkiSWBxYsPngleqpQlgbp17Wf69bp1w08SPFqbNllszz5rgxb+9S+4/faC++/rCSIKhg+36qHjxmVSPmn9emjZ0ho3ExOtHoJz7iBff21nEatWWaIITQDpP088MTYn3kuWWKf6xIl2NvLII9bZXtAWp/IEkcNWrrRJTeedZy1Ih/zx7tljVdl++MHOHFq2zJW4nMuP9u2zM4q8WvH2yy/ty+CPP9q/8pNPwllnxTqqnJNVgihguTD6VA/MDB0xIkxyULUpuDNm2OwgTw7OZalIkbybHADatrVimaNHW99ImzbWavDbb7GOLPo8QRymCRPgo4+sjfLkk8Mc8NxzNlzj3/+2YU3OuXzvmGPg2mutf2TIEPsMqF/fJgGmr8hYEEV7RbkOwNPYinKvqOojGfYPB84LbpYEjlfV8sG+msAr2LrWCnRU1RWZPVduNDFt3mx/FNWrW+vRITVzPvvM1p289FKb71DQGiudc4ANTrnvPisDX6mSVbBt3dqqLVetGuvoDk9M+iCCZUMXAxcAydia1L1UdWEmx98KNFXVfsHtL4Fhqvq5iJQG0lQ1JbPny40EMXCgtRolJto47oMsXgytWllv1rffRmd4hXMuT5kzx84ipk8/MAGvRg0b/t6ihSWM+PhMRjnmEbGaSd0SWKqqvwVBjAW6AGETBNALeCA4tgFQVFU/B1DVHVGMMyJff20tR3fdFSY5bN5sZw1Fi8LkyZ4cnCskmjWDqVNhxw7rxE5MPHB5770Dx9WpcyBhtGhhnyGHs3BVrEQzQZwErAq5nQy0CnegiJwM1AamBZvqAltE5L1g+1RgsKruy3C/gcBAgJo1a+Zo8KF277azh1q1rP3xIKrQqxcsX251m490RRnnXL5VujScfbZd0m3aZCVG0hPGjBk2Vxas9blBgwNnGrVr2/fL0EuRIoduC3cpUsQWfIpGocm8UmqjJ5AQkgCKAmcDTYHfgXFAX2BU6J1UdSQwEqyJKVrBPfKIrfv78cdhsn5iInz6qY19C/3rcM4VahUr2mj3Cy44sO2PPw4kjKQkGyb/2mtH/1ytWsH33x/942QUzQSxGutgTlc92BZOT+CWkNvJwNyQ5qlJQGsyJIjcsGgRPPywnSR06BDmgIQEKwHZt29uh+acy2dOOMFaoy+91G6r2ryqtWsPzAcJvUS6LVod49FMEIlAHRGpjSWGnsAh4z5F5DSgAjAzw33Li0gVVV0PnA/kei3vtDS44QY7axg+PMwBqpYg2reHChVyOzznXD4nYq3SebVlOmrjMFU1FRgEfAosAsar6gIRGSoinUMO7QmM1ZDhVEFT013AFyIyHxDg5WjFmplRo6xz+vHHM8nQc+ZY30P37rkdmnPORZ2X2sjEH3/YnIe4OBvCFrYWzL/+Zdlj3broL17snHNR4KU2jsBtt0FKipXxDpsc0puXzj/fk4NzrkDyBBHGRx9Zldb77rOKkmHNm2crl1xxRa7G5pxzucUTRAY7dsDNN9sY5XvuyeLAhAQbzHzZZbkWm3PO5aa8Mg8iz7j/flvx6uuvbfJJWKpWta9tW6hSJTfDc865XONnECFmz4ann7ahrW3aZHHgwoW2BqI3LznnCjBPEIHUVFtM/fjjbeZ0lhISrOe6a9dcic0552LBm5gCTz9txbYmTIig8uKECVZWo6CvZu6cK9T8DAJYscL6Hjp1gssvz+bgRYtgwQKfHOecK/AKfYJQhZtuymIJ0Yzefdd+dusW9diccy6WCn0T0+LF8NVX8N//QkQVwxMSbMXyE0+MemzOORdLhT5B1KtnrUbVq0dw8JIl8NNPmVTuc865gqXQJwiAk0+O8EBvXnLOFSKFvg/isCQk2MocUVy9zjnn8gpPEJFavtxm0vnkOOdcIeEJIlIJCfYz23GwzjlXMHiCiFRCAjRvbquLO+dcIeAJIhIrV8KsWT45zjlXqEQ1QYhIBxH5VUSWisjgMPuHi8jc4LJYRLZk2F9WRJJF5Lloxpmt996zn9685JwrRKI2zFVEigAjgAuAZCBRRCar6sL0Y1T19pDjbwWaZniYB4EZ0YoxYgkJ0KQJnHpqrCNxzrlcE80ziJbAUlX9TVX3AGOBLlkc3wsYk35DRJoDVYHPohhj9lavhu++89FLzrlCJ5oJ4iRgVcjt5GDbIUTkZKA2MC24fQzwBHBXVk8gIgNFJElEktavX58jQR8ivXnJE4RzrpDJK53UPYEEVd0X3L4ZmKKqyVndSVVHqmq8qsZXidbKbhMmQKNGWSxO7ZxzBVM0S22sBmqE3K4ebAunJ3BLyO0zgLNF5GagNHCsiOxQ1UM6uqNq7Vr45ht44IFcfVrnnMsLopkgEoE6IlIbSww9gasyHiQipwEVgJnp21S1d8j+vkB8ricHgIkTrR64Ny855wqhqDUxqWoqMAj4FFgEjFfVBSIyVEQ6hxzaExirqhqtWI5YQgLUrw8NG8Y6Euecy3WSFz+Xj0R8fLwmJSXl3AP++SdUqwb33gtDh+bc4zrnXB4iIrNVNT7cvrzSSZ33TJoEaWnevOScK7Q8QWQmIQHq1IHGjWMdiXPOxYQniHA2boRp0+zsIdtFqp1zrmDyBBHOpEmwb583LznnCjVPEOEkJFhZ76YZS0M551zh4Qkio82bYepUb15yzhV6niAymjwZUlO9eck5V+h5gsgoIQFq1oQWLWIdiXPOxZQniFBbt8Jnn3nzknPO4QniYB9+CHv2ePOSc87hCeJgCQlw0knQqlWsI3HOuZjzBJFu+3b4+GNbd/oYf1ucc84/CdN99BHs3u3NS845F/AEkS4hAU44Ac48M9aROOdcnuAJAuCvv2DKFOjWDYoUiXU0zjmXJ3iCAOt72LkTunePdSTOOZdneIIAa16qUgXOPjvWkTjnXJ4R1QQhIh1E5FcRWSoih6wpLSLDRWRucFksIluC7U1EZKaILBCReSLSI2pB7txp8x+8eck55w5SNFoPLCJFgBHABUAykCgik1V1Yfoxqnp7yPG3AunlU1OAPqq6REROBGaLyKequiXHA92yBTp3hl69cvyhnXMuP4taggBaAktV9TcAERkLdAEWZnJ8L+ABAFVdnL5RVdeIyJ9AFSDnE0S1avDOOzn+sM45l99Fs4npJGBVyO3kYNshRORkoDYwLcy+lsCxwLIw+waKSJKIJK1fvz5HgnbOOWfySid1TyBBVfeFbhSRasCbwHWqmpbxTqo6UlXjVTW+SpUquRSqc84VDtFMEKuBGiG3qwfbwukJjAndICJlgY+Ae1X1+6hE6JxzLlPRTBCJQB0RqS0ix2JJYHLGg0TkNKACMDNk27HAROANVU2IYozOOecyEbUEoaqpwCDgU2ARMF5VF4jIUBHpHHJoT2CsqmrItiuBc4C+IcNgm0QrVuecc4eSgz+X86/4+HhNSkqKdRjOOZeviMhsVY0Pty+vdFI755zLYzxBOOecC6vANDGJyHpg5VE8RGVgQw6FEw0e39Hx+I6Ox3d08nJ8J6tq2HkCBSZBHC0RScqsHS4v8PiOjsd3dDy+o5PX48uMNzE555wLyxOEc865sDxBHDAy1gFkw+M7Oh7f0fH4jk5ejy8s74NwzjkXlp9BOOecC8sThHPOubAKVYKIYAnU40RkXLD/BxGplYux1RCR6SKyMFhq9R9hjmkrIltD6lPdn1vxhcSwQkTmB89/SG0TMc8E7+E8EWmWi7HVC3lv5orINhG5LcMxufoeisirIvKniPwcsq2iiHwuIkuCnxUyue+1wTFLROTaXIzvMRH5Jfj9TRSR8pncN8u/hSjGN0REVof8Djtmct8s/9+jGN+4kNhWiMjcTO4b9ffvqKlqobgARbBFh07BFiD6CWiQ4ZibgReD6z2BcbkYXzWgWXC9DLA4THxtgQ9j/D6uACpnsb8j8DEgQGvghxj+vv/AJgHF7D3Eik42A34O2fYoMDi4Phj4X5j7VQR+C35WCK5XyKX4LgSKBtf/Fy6+SP4WohjfEOCuCH7/Wf6/Ryu+DPufAO6P1ft3tJfCdAaxfwlUVd0DpC+BGqoL8HpwPQFoJyKSG8Gp6lpVnRNc345VwA27Al8e1wUr065q63iUDxZ+ym3tgGWqejSz64+aqs4ANmXYHPp39jpwWZi7XgR8rqqbVHUz8DnQITfiU9XP1KoxA3yPreUSE5m8f5GI5P/9qGUVX/DZcSUZ1rrJTwpTgohkCdT9xwT/IFuBSrkSXYigaasp8EOY3WeIyE8i8rGINMzVwIwCn4nIbBEZGGZ/xEvNRtkhi1CFiPV7WFVV1wbX/wCqhjkmr7yP/bAzwnCy+1uIpkFBE9irmTTR5YX372xgnaouyWR/LN+/iBSmBJEviEhp4F3gNlXdlmH3HKzJJA54FpiU2/EBbVS1GXAxcIuInBODGLIktuBUZ2BCmN154T3cT62tIU+ONReRe4FU4O1MDonV38ILwN+AJsBarBknL+pF1mcPef5/qTAliEiWQN1/jIgUBcoBG3MlOnvOYlhyeFtV38u4X1W3qeqO4PoUoJiIVM6t+ILnXR38/BNb9a9lhkMOZ6nZaLkYmKOq6zLuyAvvIbAuvdkt+PlnmGNi+j6KSF+gE9A7SGKHiOBvISpUdZ2q7lNbp/7lTJ431u9fUaAbMC6zY2L1/h2OwpQgIlkCdTKQPlrkCmBaZv8cOS1orxwFLFLVJzM55oT0PhERaYn9/nIzgZUSkTLp17HOzJ8zHDYZ6BOMZmoNbA1pTsktmX5zi/V7GAj9O7sWeD/MMZ8CF4pIhaAJ5cJgW9SJSAfgbqCzqqZkckwkfwvRii+0T6trJs8b0ZLHUdQe+EVVk8PtjOX7d1hi3UuemxdshM1ibHTDvcG2odg/AkBxrFliKTALOCUXY2uDNTXMA+YGl47AjcCNwTGDgAXYiIzvgTNz+f07JXjun4I40t/D0BgFGBG8x/OB+FyOsRT2HT4ieQAAAl9JREFUgV8uZFvM3kMsUa0F9mLt4P2xfq0vgCXAVKBicGw88ErIffsFf4tLgetyMb6lWPt9+t9h+si+E4EpWf0t5FJ8bwZ/W/OwD/1qGeMLbh/y/54b8QXbR6f/zYUcm+vv39FevNSGc865sApTE5NzzrnD4AnCOedcWJ4gnHPOheUJwjnnXFieIJxzzoXlCcK5bIjIvgxVYnOsMqiI1AqtBOpcXlI01gE4lw/sVNUmsQ7CudzmZxDOHaGgnv+jQU3/WSJyarC9lohMC4rJfSEiNYPtVYP1FX4KLmcGD1VERF4WWwfkMxEpERz/d7H1QeaJyNgYvUxXiHmCcC57JTI0MfUI2bdVVRsDzwFPBdueBV5X1dOxQnfPBNufAb5SKxTYDJtBC1AHGKGqDYEtwOXB9sFA0+BxbozWi3MuMz6T2rlsiMgOVS0dZvsK4HxV/S0otPiHqlYSkQ1Y+Ye9wfa1qlpZRNYD1VV1d8hj1MLWfagT3L4HKKaqD4nIJ8AOrOLsJA2KDDqXW/wMwrmjo5lcPxy7Q67v40Df4CVYXatmQGJQIdS5XOMJwrmj0yPk58zg+ndY9VCA3sDXwfUvgJsARKSIiJTL7EFF5BighqpOB+7BSs8fchbjXDT5NxLnslciw8Lzn6hq+lDXCiIyDzsL6BVsuxV4TUT+CawHrgu2/wMYKSL9sTOFm7BKoOEUAd4KkogAz6jqlhx7Rc5FwPsgnDtCQR9EvKpuiHUszkWDNzE555wLy88gnHPOheVnEM4558LyBOGccy4sTxDOOefC8gThnHMuLE8Qzjnnwvp/oQldQas3TDwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "#------------------------------------------------\n",
    "# Plot training and validation accuracy per epoch\n",
    "#------------------------------------------------\n",
    "plt.plot(epochs, acc, 'r')\n",
    "plt.plot(epochs, val_acc, 'b')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend([\"Accuracy\", \"Validation Accuracy\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "attempted-needle",
   "metadata": {},
   "source": [
    "A more rigorous way of setting the passing threshold of this assignment is to use the slope of your `val_loss` curve.\n",
    "\n",
    "**To pass this assignment the slope of your `val_loss` curve should be 0.0005 at maximum.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "constant-cursor",
   "metadata": {
    "tags": [
     "graded"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slope of your validation loss curve is 0.00646\n"
     ]
    }
   ],
   "source": [
    "# Test the slope of your val_loss curve\n",
    "slope, *_ = linregress(epochs, val_loss)\n",
    "print(f\"The slope of your validation loss curve is {slope:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "touched-sharing",
   "metadata": {},
   "source": [
    "**If your model generated a validation loss curve that meets the criteria above, run the following cell and then submit your assignment for grading. Otherwise, try with a different architecture.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "flexible-gravity",
   "metadata": {
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "with open('history.pkl', 'wb') as f:\n",
    "    pickle.dump(history.history, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "junior-triumph",
   "metadata": {},
   "source": [
    "**Congratulations on finishing this week's assignment!**\n",
    "\n",
    "You have successfully implemented a neural network capable of classifying sentiment in text data while doing a fairly good job of not overfitting! Nice job!\n",
    "\n",
    "**Keep it up!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
